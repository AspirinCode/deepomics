{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GTX 980 (CNMeM is disabled, cuDNN 5105)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function \n",
    "import os, sys, h5py\n",
    "import numpy as np\n",
    "from six.moves import cPickle\n",
    "from collections import OrderedDict\n",
    "\n",
    "sys.path.append('/home/peter/Code/deepomics')\n",
    "from neuralnetwork import NeuralNet, NeuralTrainer\n",
    "import train as fit \n",
    "import visualize, utils\n",
    "\n",
    "from lasagne import layers, nonlinearities, updates, objectives, init \n",
    "from lasagne.layers import get_output, get_output_shape, get_all_params\n",
    "import theano.tensor as T\n",
    "import theano\n",
    "np.random.seed(247) # for reproducibility\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 324 ms, sys: 596 ms, total: 920 ms\n",
      "Wall time: 920 ms\n"
     ]
    }
   ],
   "source": [
    "filename = 'processed_dataset.hdf5'\n",
    "data_path = '/home/peter/Code/tensorflow/data'\n",
    "file_path = os.path.join(data_path, filename)\n",
    "group_name = ['processed_data']\n",
    "dataset = h5py.File(file_path,'r')\n",
    "%time dtf = np.array(dataset['/'+group_name[0]+'/dtf'])\n",
    "ltf = np.array(dataset['/'+group_name[0]+'/ltf'])\n",
    "dtf_crossval = np.array(dataset['/'+group_name[0]+'/dtf_crossval'])\n",
    "ltf_crossval = np.array(dataset['/'+group_name[0]+'/ltf_crossval'])\n",
    "\n",
    "train = (dtf.transpose([0,3,1,2]), ltf)\n",
    "valid = (dtf_crossval.transpose([0,3,1,2]), ltf_crossval)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# original model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compiling model\n"
     ]
    }
   ],
   "source": [
    "def build_model(shape, num_labels):\n",
    "\n",
    "    # get model\n",
    "    input_var = T.tensor4('inputs')\n",
    "    target_var = T.dmatrix('targets')\n",
    "\n",
    "    net = {}\n",
    "    net['input'] = layers.InputLayer(input_var=input_var, shape=shape)\n",
    "    net['conv1'] = layers.Conv2DLayer(net['input'], num_filters=18, filter_size=(2, 5), stride=(1, 1),    # 1000\n",
    "                                        W=init.HeNormal(), b=init.Constant(0.1), \n",
    "                                      nonlinearity=nonlinearities.tanh, pad='valid')\n",
    "\n",
    "    net['conv2'] = layers.Conv2DLayer(net['conv1'], num_filters=40, filter_size=(2, 5), stride=(1, 1), # 18\n",
    "                                        W=init.HeNormal(), b=init.Constant(0.1), \n",
    "                                      nonlinearity=nonlinearities.tanh, pad='valid')\n",
    "    net['conv2_pool'] = layers.MaxPool2DLayer(net['conv2'], pool_size=(1, 10), stride=(1, 10)) # 25\n",
    "\n",
    "    net['conv3'] = layers.Conv2DLayer(net['conv2_pool'], num_filters=15, filter_size=(1, 1), stride=(1, 1), # 18\n",
    "                                        W=init.HeNormal(), b=init.Constant(0.1), \n",
    "                                      nonlinearity=nonlinearities.tanh, pad='valid')\n",
    "\n",
    "    net['dense1'] = layers.DenseLayer(net['conv3'], num_units=100, W=init.HeNormal(), \n",
    "                                     b=init.Constant(), nonlinearity=nonlinearities.rectify)\n",
    "    \n",
    "    net['output'] = layers.DenseLayer(net['dense1'], num_units=num_labels, W=init.HeNormal(), \n",
    "                                     b=init.Constant(), nonlinearity=nonlinearities.sigmoid)\n",
    "    \n",
    "    # optimization parameters\n",
    "    optimization = {\"objective\": \"binary\",\n",
    "                    \"optimizer\": \"adam\",\n",
    "                    \"learning_rate\": 0.001, \n",
    "                    \"l2\": 1e-6\n",
    "                    }\n",
    "\n",
    "    return net, input_var, target_var, optimization\n",
    "\n",
    "# build network\n",
    "shape = (None, train[0].shape[1], train[0].shape[2], train[0].shape[3])\n",
    "num_labels = train[1].shape[1]\n",
    "net, input_var, target_var, optimization = build_model(shape, num_labels)\n",
    "\n",
    "# build neural network class\n",
    "nnmodel = NeuralNet(net, input_var, target_var)\n",
    "#nnmodel.inspect_layers()\n",
    "\n",
    "# set output file paths\n",
    "resultspath = utils.make_directory('../results', 'deepomics')\n",
    "output_name = 'original_model'\n",
    "filepath = os.path.join(resultspath, output_name)\n",
    "nntrainer = NeuralTrainer(nnmodel, optimization, save='best', filepath=filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.40137 -- accuracy=83.96%  \n",
      "  valid loss:\t\t0.37519\n",
      "  valid accuracy:\t0.85309+/-0.00006\n",
      "  valid auc-roc:\t0.90830+/-0.00002\n",
      "  valid auc-pr:\t\t0.89853+/-0.00614\n",
      "saving model parameters to: ../results/test/original_model_best.pickle\n",
      "Epoch 2 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.37267 -- accuracy=85.35%  \n",
      "  valid loss:\t\t0.36890\n",
      "  valid accuracy:\t0.85491+/-0.00003\n",
      "  valid auc-roc:\t0.91288+/-0.00002\n",
      "  valid auc-pr:\t\t0.90612+/-0.00803\n",
      "saving model parameters to: ../results/test/original_model_best.pickle\n",
      "Epoch 3 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.36676 -- accuracy=85.54%  \n",
      "  valid loss:\t\t0.36356\n",
      "  valid accuracy:\t0.85665+/-0.00001\n",
      "  valid auc-roc:\t0.91432+/-0.00001\n",
      "  valid auc-pr:\t\t0.90777+/-0.00744\n",
      "saving model parameters to: ../results/test/original_model_best.pickle\n",
      "Epoch 4 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.36314 -- accuracy=85.67%  \n",
      "  valid loss:\t\t0.36119\n",
      "  valid accuracy:\t0.85669+/-0.00000\n",
      "  valid auc-roc:\t0.91542+/-0.00000\n",
      "  valid auc-pr:\t\t0.90929+/-0.00713\n",
      "saving model parameters to: ../results/test/original_model_best.pickle\n",
      "Epoch 5 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.36019 -- accuracy=85.80%  \n",
      "  valid loss:\t\t0.37366\n",
      "  valid accuracy:\t0.85379+/-0.00001\n",
      "  valid auc-roc:\t0.91603+/-0.00001\n",
      "  valid auc-pr:\t\t0.90999+/-0.00681\n",
      "Epoch 6 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.35823 -- accuracy=85.86%  \n",
      "  valid loss:\t\t0.35703\n",
      "  valid accuracy:\t0.85875+/-0.00005\n",
      "  valid auc-roc:\t0.91754+/-0.00001\n",
      "  valid auc-pr:\t\t0.91175+/-0.00705\n",
      "saving model parameters to: ../results/test/original_model_best.pickle\n",
      "Epoch 7 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.35579 -- accuracy=85.95%  \n",
      "  valid loss:\t\t0.35795\n",
      "  valid accuracy:\t0.85855+/-0.00001\n",
      "  valid auc-roc:\t0.91776+/-0.00001\n",
      "  valid auc-pr:\t\t0.91206+/-0.00699\n",
      "Epoch 8 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.35426 -- accuracy=86.02%  \n",
      "  valid loss:\t\t0.35726\n",
      "  valid accuracy:\t0.85856+/-0.00002\n",
      "  valid auc-roc:\t0.91834+/-0.00001\n",
      "  valid auc-pr:\t\t0.91271+/-0.00639\n",
      "Epoch 9 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.35269 -- accuracy=86.05%  \n",
      "  valid loss:\t\t0.35408\n",
      "  valid accuracy:\t0.85972+/-0.00003\n",
      "  valid auc-roc:\t0.91877+/-0.00001\n",
      "  valid auc-pr:\t\t0.91318+/-0.00672\n",
      "saving model parameters to: ../results/test/original_model_best.pickle\n",
      "Epoch 10 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.35095 -- accuracy=86.14%  \n",
      "  valid loss:\t\t0.35467\n",
      "  valid accuracy:\t0.85988+/-0.00004\n",
      "  valid auc-roc:\t0.91924+/-0.00000\n",
      "  valid auc-pr:\t\t0.91362+/-0.00668\n",
      "Epoch 11 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.34913 -- accuracy=86.18%  \n",
      "  valid loss:\t\t0.35595\n",
      "  valid accuracy:\t0.85936+/-0.00009\n",
      "  valid auc-roc:\t0.91916+/-0.00000\n",
      "  valid auc-pr:\t\t0.91365+/-0.00644\n",
      "Epoch 12 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.34807 -- accuracy=86.22%  \n",
      "  valid loss:\t\t0.35404\n",
      "  valid accuracy:\t0.85987+/-0.00001\n",
      "  valid auc-roc:\t0.91950+/-0.00001\n",
      "  valid auc-pr:\t\t0.91386+/-0.00649\n",
      "saving model parameters to: ../results/test/original_model_best.pickle\n",
      "Epoch 13 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.34641 -- accuracy=86.27%  \n",
      "  valid loss:\t\t0.35325\n",
      "  valid accuracy:\t0.86060+/-0.00007\n",
      "  valid auc-roc:\t0.91935+/-0.00001\n",
      "  valid auc-pr:\t\t0.91368+/-0.00598\n",
      "saving model parameters to: ../results/test/original_model_best.pickle\n",
      "Epoch 14 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.34480 -- accuracy=86.34%  \n",
      "  valid loss:\t\t0.35227\n",
      "  valid accuracy:\t0.86052+/-0.00003\n",
      "  valid auc-roc:\t0.91996+/-0.00000\n",
      "  valid auc-pr:\t\t0.91447+/-0.00611\n",
      "saving model parameters to: ../results/test/original_model_best.pickle\n",
      "Epoch 15 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.34411 -- accuracy=86.38%  \n",
      "  valid loss:\t\t0.35311\n",
      "  valid accuracy:\t0.86074+/-0.00007\n",
      "  valid auc-roc:\t0.91957+/-0.00000\n",
      "  valid auc-pr:\t\t0.91396+/-0.00608\n",
      "Epoch 16 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.34252 -- accuracy=86.43%  \n",
      "  valid loss:\t\t0.35598\n",
      "  valid accuracy:\t0.85944+/-0.00006\n",
      "  valid auc-roc:\t0.91915+/-0.00000\n",
      "  valid auc-pr:\t\t0.91355+/-0.00627\n",
      "Epoch 17 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.34159 -- accuracy=86.44%  \n",
      "  valid loss:\t\t0.35311\n",
      "  valid accuracy:\t0.86062+/-0.00006\n",
      "  valid auc-roc:\t0.91969+/-0.00001\n",
      "  valid auc-pr:\t\t0.91412+/-0.00607\n",
      "Epoch 18 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.34026 -- accuracy=86.49%  \n",
      "  valid loss:\t\t0.35400\n",
      "  valid accuracy:\t0.86023+/-0.00002\n",
      "  valid auc-roc:\t0.91938+/-0.00001\n",
      "  valid auc-pr:\t\t0.91385+/-0.00591\n",
      "Epoch 19 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.33941 -- accuracy=86.51%  \n",
      "  valid loss:\t\t0.36212\n",
      "  valid accuracy:\t0.85737+/-0.00003\n",
      "  valid auc-roc:\t0.91907+/-0.00000\n",
      "  valid auc-pr:\t\t0.91342+/-0.00601\n",
      "Epoch 20 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.33811 -- accuracy=86.56%  \n",
      "  valid loss:\t\t0.35384\n",
      "  valid accuracy:\t0.86070+/-0.00001\n",
      "  valid auc-roc:\t0.91982+/-0.00001\n",
      "  valid auc-pr:\t\t0.91440+/-0.00585\n",
      "Epoch 21 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.33710 -- accuracy=86.60%  \n",
      "  valid loss:\t\t0.35802\n",
      "  valid accuracy:\t0.85792+/-0.00002\n",
      "  valid auc-roc:\t0.91971+/-0.00000\n",
      "  valid auc-pr:\t\t0.91417+/-0.00561\n",
      "Epoch 22 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.33591 -- accuracy=86.64%  \n",
      "  valid loss:\t\t0.35621\n",
      "  valid accuracy:\t0.85829+/-0.00004\n",
      "  valid auc-roc:\t0.91881+/-0.00002\n",
      "  valid auc-pr:\t\t0.91324+/-0.00591\n",
      "Epoch 23 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.33509 -- accuracy=86.70%  \n",
      "  valid loss:\t\t0.35508\n",
      "  valid accuracy:\t0.85991+/-0.00001\n",
      "  valid auc-roc:\t0.91897+/-0.00000\n",
      "  valid auc-pr:\t\t0.91327+/-0.00600\n",
      "Epoch 24 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.33395 -- accuracy=86.74%  \n",
      "  valid loss:\t\t0.35529\n",
      "  valid accuracy:\t0.86017+/-0.00001\n",
      "  valid auc-roc:\t0.91920+/-0.00001\n",
      "  valid auc-pr:\t\t0.91357+/-0.00586\n",
      "Epoch 25 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.33365 -- accuracy=86.74%  \n",
      "  valid loss:\t\t0.35736\n",
      "  valid accuracy:\t0.85930+/-0.00003\n",
      "  valid auc-roc:\t0.91840+/-0.00002\n",
      "  valid auc-pr:\t\t0.91263+/-0.00590\n",
      "Patience ran out... Early stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<neuralnetwork.NeuralTrainer instance at 0x7f26ef154998>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train model\n",
    "fit.train_minibatch(nntrainer, data={'train': train, 'valid': valid}, \n",
    "                              batch_size=1000, num_epochs=500, patience=10, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  test  loss:\t\t0.35232\n",
      "  test  accuracy:\t0.86048+/-0.00003\n",
      "  test  auc-roc:\t0.91995+/-0.00000\n",
      "  test  auc-pr:\t\t0.91446+/-0.00609\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.35231954771865853"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nntrainer.set_best_parameters()\n",
    "\n",
    "# test model\n",
    "nntrainer.test_model(valid, batch_size=100, name=\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# original model w/ batch norm and dropout and relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compiling model\n"
     ]
    }
   ],
   "source": [
    "def build_model(shape, num_labels):\n",
    "\n",
    "    # get model\n",
    "    input_var = T.tensor4('inputs')\n",
    "    target_var = T.dmatrix('targets')\n",
    "\n",
    "    net = {}\n",
    "    net['input'] = layers.InputLayer(input_var=input_var, shape=shape)\n",
    "    net['conv1'] = layers.Conv2DLayer(net['input'], num_filters=18, filter_size=(2, 5), stride=(1, 1),    # 1000\n",
    "                                        W=init.HeNormal(), b=None, nonlinearity=None, pad='valid')\n",
    "    net['conv1_norm'] = layers.BatchNormLayer(net['conv1'])\n",
    "    net['conv1_active'] = layers.NonlinearityLayer(net['conv1_norm'], nonlinearity=nonlinearities.rectify)\n",
    "    net['conv1_dropout'] = layers.DropoutLayer(net['conv1_active'], p=0.1)\n",
    "\n",
    "    net['conv2'] = layers.Conv2DLayer(net['conv1_dropout'], num_filters=40, filter_size=(2, 5), stride=(1, 1), # 18\n",
    "                                        W=init.HeNormal(), b=None, nonlinearity=None, pad='valid')\n",
    "    net['conv2_norm'] = layers.BatchNormLayer(net['conv2'])\n",
    "    net['conv2_active'] = layers.NonlinearityLayer(net['conv2_norm'], nonlinearity=nonlinearities.rectify)\n",
    "    net['conv2_pool'] = layers.MaxPool2DLayer(net['conv2_active'], pool_size=(1, 10), stride=(1, 10)) # 25\n",
    "    net['conv2_dropout'] = layers.DropoutLayer(net['conv2_pool'], p=0.1)\n",
    "\n",
    "    net['conv3'] = layers.Conv2DLayer(net['conv2_dropout'], num_filters=15, filter_size=(1, 1), stride=(1, 1), # 18\n",
    "                                        W=init.HeNormal(), b=None, nonlinearity=None, pad='valid')\n",
    "    net['conv3_norm'] = layers.BatchNormLayer(net['conv3'])\n",
    "    net['conv3_active'] = layers.NonlinearityLayer(net['conv3_norm'], nonlinearity=nonlinearities.rectify)\n",
    "    net['conv3_dropout'] = layers.DropoutLayer(net['conv3_active'], p=0.1)\n",
    "\n",
    "    net['dense1'] = layers.DenseLayer(net['conv3_dropout'], num_units=100, W=init.HeNormal(), \n",
    "                                     b=init.Constant(), nonlinearity=None)\n",
    "    net['dense1_active'] = layers.NonlinearityLayer(net['dense1'], nonlinearity=nonlinearities.rectify)\n",
    "    net['dense1_dropout'] = layers.DropoutLayer(net['dense1_active'], p=0.3)\n",
    "    \n",
    "    net['dense2'] = layers.DenseLayer(net['dense1_dropout'], num_units=num_labels, W=init.HeNormal(), \n",
    "                                     b=init.Constant(), nonlinearity=None)\n",
    "    net['output'] = layers.NonlinearityLayer(net['dense2'], nonlinearity=nonlinearities.sigmoid)\n",
    "    \n",
    "    # optimization parameters\n",
    "    optimization = {\"objective\": \"binary\",\n",
    "                    \"optimizer\": \"adam\",\n",
    "                    \"learning_rate\": 0.001, \n",
    "                    \"l2\": 1e-6\n",
    "                    }\n",
    "\n",
    "    return net, input_var, target_var, optimization\n",
    "\n",
    "# build network\n",
    "shape = (None, train[0].shape[1], train[0].shape[2], train[0].shape[3])\n",
    "num_labels = train[1].shape[1]\n",
    "net, input_var, target_var, optimization = build_model(shape, num_labels)\n",
    "\n",
    "# build neural network class\n",
    "nnmodel = NeuralNet(net, input_var, target_var)\n",
    "#nnmodel.inspect_layers()\n",
    "\n",
    "# set output file paths\n",
    "resultspath = utils.make_directory('../results', 'deepomics')\n",
    "output_name = 'original_model_bells'\n",
    "filepath = os.path.join(resultspath, output_name)\n",
    "nntrainer = NeuralTrainer(nnmodel, optimization, save='best', filepath=filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.39669 -- accuracy=84.36%  \n",
      "  valid loss:\t\t0.36735\n",
      "  valid accuracy:\t0.85635+/-0.00004\n",
      "  valid auc-roc:\t0.91488+/-0.00000\n",
      "  valid auc-pr:\t\t0.90728+/-0.00652\n",
      "saving model parameters to: ../results/test/original_model_bells_best.pickle\n",
      "Epoch 2 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.36848 -- accuracy=85.59%  \n",
      "  valid loss:\t\t0.35560\n",
      "  valid accuracy:\t0.85806+/-0.00003\n",
      "  valid auc-roc:\t0.91884+/-0.00002\n",
      "  valid auc-pr:\t\t0.91258+/-0.00579\n",
      "saving model parameters to: ../results/test/original_model_bells_best.pickle\n",
      "Epoch 3 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.36197 -- accuracy=85.82%  \n",
      "  valid loss:\t\t0.35319\n",
      "  valid accuracy:\t0.86026+/-0.00001\n",
      "  valid auc-roc:\t0.92048+/-0.00000\n",
      "  valid auc-pr:\t\t0.91454+/-0.00537\n",
      "saving model parameters to: ../results/test/original_model_bells_best.pickle\n",
      "Epoch 4 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.35791 -- accuracy=85.97%  \n",
      "  valid loss:\t\t0.35093\n",
      "  valid accuracy:\t0.86025+/-0.00000\n",
      "  valid auc-roc:\t0.92252+/-0.00000\n",
      "  valid auc-pr:\t\t0.91734+/-0.00456\n",
      "saving model parameters to: ../results/test/original_model_bells_best.pickle\n",
      "Epoch 5 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.35532 -- accuracy=86.07%  \n",
      "  valid loss:\t\t0.34769\n",
      "  valid accuracy:\t0.86207+/-0.00002\n",
      "  valid auc-roc:\t0.92281+/-0.00000\n",
      "  valid auc-pr:\t\t0.91766+/-0.00449\n",
      "saving model parameters to: ../results/test/original_model_bells_best.pickle\n",
      "Epoch 6 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.35315 -- accuracy=86.18%  \n",
      "  valid loss:\t\t0.34477\n",
      "  valid accuracy:\t0.86325+/-0.00000\n",
      "  valid auc-roc:\t0.92451+/-0.00000\n",
      "  valid auc-pr:\t\t0.91957+/-0.00396\n",
      "saving model parameters to: ../results/test/original_model_bells_best.pickle\n",
      "Epoch 7 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.35100 -- accuracy=86.24%  \n",
      "  valid loss:\t\t0.34406\n",
      "  valid accuracy:\t0.86341+/-0.00001\n",
      "  valid auc-roc:\t0.92489+/-0.00000\n",
      "  valid auc-pr:\t\t0.92016+/-0.00330\n",
      "saving model parameters to: ../results/test/original_model_bells_best.pickle\n",
      "Epoch 8 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.34987 -- accuracy=86.28%  \n",
      "  valid loss:\t\t0.34281\n",
      "  valid accuracy:\t0.86337+/-0.00001\n",
      "  valid auc-roc:\t0.92547+/-0.00000\n",
      "  valid auc-pr:\t\t0.92087+/-0.00356\n",
      "saving model parameters to: ../results/test/original_model_bells_best.pickle\n",
      "Epoch 9 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.34879 -- accuracy=86.32%  \n",
      "  valid loss:\t\t0.34189\n",
      "  valid accuracy:\t0.86368+/-0.00001\n",
      "  valid auc-roc:\t0.92609+/-0.00000\n",
      "  valid auc-pr:\t\t0.92168+/-0.00336\n",
      "saving model parameters to: ../results/test/original_model_bells_best.pickle\n",
      "Epoch 10 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.34828 -- accuracy=86.32%  \n",
      "  valid loss:\t\t0.34372\n",
      "  valid accuracy:\t0.86409+/-0.00000\n",
      "  valid auc-roc:\t0.92626+/-0.00000\n",
      "  valid auc-pr:\t\t0.92181+/-0.00323\n",
      "Epoch 11 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.34722 -- accuracy=86.37%  \n",
      "  valid loss:\t\t0.34135\n",
      "  valid accuracy:\t0.86475+/-0.00001\n",
      "  valid auc-roc:\t0.92646+/-0.00000\n",
      "  valid auc-pr:\t\t0.92182+/-0.00361\n",
      "saving model parameters to: ../results/test/original_model_bells_best.pickle\n",
      "Epoch 12 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.34669 -- accuracy=86.39%  \n",
      "  valid loss:\t\t0.34176\n",
      "  valid accuracy:\t0.86456+/-0.00000\n",
      "  valid auc-roc:\t0.92692+/-0.00000\n",
      "  valid auc-pr:\t\t0.92259+/-0.00323\n",
      "Epoch 13 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.34627 -- accuracy=86.37%  \n",
      "  valid loss:\t\t0.34038\n",
      "  valid accuracy:\t0.86439+/-0.00000\n",
      "  valid auc-roc:\t0.92716+/-0.00000\n",
      "  valid auc-pr:\t\t0.92293+/-0.00316\n",
      "saving model parameters to: ../results/test/original_model_bells_best.pickle\n",
      "Epoch 14 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.34610 -- accuracy=86.38%  \n",
      "  valid loss:\t\t0.33905\n",
      "  valid accuracy:\t0.86469+/-0.00000\n",
      "  valid auc-roc:\t0.92734+/-0.00000\n",
      "  valid auc-pr:\t\t0.92311+/-0.00311\n",
      "saving model parameters to: ../results/test/original_model_bells_best.pickle\n",
      "Epoch 15 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.34530 -- accuracy=86.42%  \n",
      "  valid loss:\t\t0.34027\n",
      "  valid accuracy:\t0.86506+/-0.00000\n",
      "  valid auc-roc:\t0.92738+/-0.00000\n",
      "  valid auc-pr:\t\t0.92325+/-0.00317\n",
      "Epoch 16 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.34533 -- accuracy=86.40%  \n",
      "  valid loss:\t\t0.34280\n",
      "  valid accuracy:\t0.86422+/-0.00000\n",
      "  valid auc-roc:\t0.92765+/-0.00000\n",
      "  valid auc-pr:\t\t0.92369+/-0.00260\n",
      "Epoch 17 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.34460 -- accuracy=86.43%  \n",
      "  valid loss:\t\t0.33974\n",
      "  valid accuracy:\t0.86507+/-0.00000\n",
      "  valid auc-roc:\t0.92781+/-0.00000\n",
      "  valid auc-pr:\t\t0.92381+/-0.00290\n",
      "Epoch 18 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.34414 -- accuracy=86.45%  \n",
      "  valid loss:\t\t0.33895\n",
      "  valid accuracy:\t0.86534+/-0.00000\n",
      "  valid auc-roc:\t0.92773+/-0.00000\n",
      "  valid auc-pr:\t\t0.92365+/-0.00305\n",
      "saving model parameters to: ../results/test/original_model_bells_best.pickle\n",
      "Epoch 19 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.34377 -- accuracy=86.43%  \n",
      "  valid loss:\t\t0.33971\n",
      "  valid accuracy:\t0.86520+/-0.00000\n",
      "  valid auc-roc:\t0.92802+/-0.00000\n",
      "  valid auc-pr:\t\t0.92405+/-0.00296\n",
      "Epoch 20 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.34357 -- accuracy=86.45%  \n",
      "  valid loss:\t\t0.33722\n",
      "  valid accuracy:\t0.86509+/-0.00000\n",
      "  valid auc-roc:\t0.92818+/-0.00000\n",
      "  valid auc-pr:\t\t0.92430+/-0.00294\n",
      "saving model parameters to: ../results/test/original_model_bells_best.pickle\n",
      "Epoch 21 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.34333 -- accuracy=86.48%  \n",
      "  valid loss:\t\t0.33909\n",
      "  valid accuracy:\t0.86517+/-0.00000\n",
      "  valid auc-roc:\t0.92832+/-0.00000\n",
      "  valid auc-pr:\t\t0.92450+/-0.00279\n",
      "Epoch 22 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.34263 -- accuracy=86.46%  \n",
      "  valid loss:\t\t0.33769\n",
      "  valid accuracy:\t0.86522+/-0.00000\n",
      "  valid auc-roc:\t0.92863+/-0.00000\n",
      "  valid auc-pr:\t\t0.92469+/-0.00280\n",
      "Epoch 23 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.34264 -- accuracy=86.49%  \n",
      "  valid loss:\t\t0.34088\n",
      "  valid accuracy:\t0.86429+/-0.00000\n",
      "  valid auc-roc:\t0.92849+/-0.00000\n",
      "  valid auc-pr:\t\t0.92471+/-0.00276\n",
      "Epoch 24 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.34238 -- accuracy=86.50%  \n",
      "  valid loss:\t\t0.33564\n",
      "  valid accuracy:\t0.86559+/-0.00000\n",
      "  valid auc-roc:\t0.92873+/-0.00000\n",
      "  valid auc-pr:\t\t0.92495+/-0.00255\n",
      "saving model parameters to: ../results/test/original_model_bells_best.pickle\n",
      "Epoch 25 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.34217 -- accuracy=86.47%  \n",
      "  valid loss:\t\t0.33637\n",
      "  valid accuracy:\t0.86572+/-0.00000\n",
      "  valid auc-roc:\t0.92870+/-0.00000\n",
      "  valid auc-pr:\t\t0.92465+/-0.00284\n",
      "Epoch 26 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.34192 -- accuracy=86.49%  \n",
      "  valid loss:\t\t0.33593\n",
      "  valid accuracy:\t0.86577+/-0.00000\n",
      "  valid auc-roc:\t0.92888+/-0.00000\n",
      "  valid auc-pr:\t\t0.92503+/-0.00259\n",
      "Epoch 27 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.34167 -- accuracy=86.51%  \n",
      "  valid loss:\t\t0.33603\n",
      "  valid accuracy:\t0.86586+/-0.00000\n",
      "  valid auc-roc:\t0.92897+/-0.00000\n",
      "  valid auc-pr:\t\t0.92524+/-0.00250\n",
      "Epoch 28 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.34145 -- accuracy=86.52%  \n",
      "  valid loss:\t\t0.33798\n",
      "  valid accuracy:\t0.86537+/-0.00000\n",
      "  valid auc-roc:\t0.92875+/-0.00000\n",
      "  valid auc-pr:\t\t0.92486+/-0.00287\n",
      "Epoch 29 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.34139 -- accuracy=86.54%  \n",
      "  valid loss:\t\t0.33575\n",
      "  valid accuracy:\t0.86619+/-0.00000\n",
      "  valid auc-roc:\t0.92909+/-0.00000\n",
      "  valid auc-pr:\t\t0.92534+/-0.00243\n",
      "Epoch 30 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.34146 -- accuracy=86.54%  \n",
      "  valid loss:\t\t0.33546\n",
      "  valid accuracy:\t0.86610+/-0.00000\n",
      "  valid auc-roc:\t0.92916+/-0.00000\n",
      "  valid auc-pr:\t\t0.92540+/-0.00252\n",
      "saving model parameters to: ../results/test/original_model_bells_best.pickle\n",
      "Epoch 31 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.34111 -- accuracy=86.57%  \n",
      "  valid loss:\t\t0.33808\n",
      "  valid accuracy:\t0.86536+/-0.00000\n",
      "  valid auc-roc:\t0.92942+/-0.00000\n",
      "  valid auc-pr:\t\t0.92575+/-0.00226\n",
      "Epoch 32 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.34090 -- accuracy=86.57%  \n",
      "  valid loss:\t\t0.33556\n",
      "  valid accuracy:\t0.86574+/-0.00000\n",
      "  valid auc-roc:\t0.92924+/-0.00000\n",
      "  valid auc-pr:\t\t0.92539+/-0.00257\n",
      "Epoch 33 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.34062 -- accuracy=86.58%  \n",
      "  valid loss:\t\t0.33600\n",
      "  valid accuracy:\t0.86570+/-0.00000\n",
      "  valid auc-roc:\t0.92951+/-0.00000\n",
      "  valid auc-pr:\t\t0.92581+/-0.00232\n",
      "Epoch 34 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.34052 -- accuracy=86.58%  \n",
      "  valid loss:\t\t0.33502\n",
      "  valid accuracy:\t0.86613+/-0.00000\n",
      "  valid auc-roc:\t0.92927+/-0.00000\n",
      "  valid auc-pr:\t\t0.92539+/-0.00261\n",
      "saving model parameters to: ../results/test/original_model_bells_best.pickle\n",
      "Epoch 35 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.34033 -- accuracy=86.57%  \n",
      "  valid loss:\t\t0.33489\n",
      "  valid accuracy:\t0.86646+/-0.00000\n",
      "  valid auc-roc:\t0.92949+/-0.00000\n",
      "  valid auc-pr:\t\t0.92570+/-0.00238\n",
      "saving model parameters to: ../results/test/original_model_bells_best.pickle\n",
      "Epoch 36 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.34012 -- accuracy=86.59%  \n",
      "  valid loss:\t\t0.33468\n",
      "  valid accuracy:\t0.86616+/-0.00000\n",
      "  valid auc-roc:\t0.92945+/-0.00000\n",
      "  valid auc-pr:\t\t0.92580+/-0.00230\n",
      "saving model parameters to: ../results/test/original_model_bells_best.pickle\n",
      "Epoch 37 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.34036 -- accuracy=86.59%  \n",
      "  valid loss:\t\t0.33484\n",
      "  valid accuracy:\t0.86640+/-0.00000\n",
      "  valid auc-roc:\t0.92930+/-0.00000\n",
      "  valid auc-pr:\t\t0.92540+/-0.00258\n",
      "Epoch 38 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.34026 -- accuracy=86.56%  \n",
      "  valid loss:\t\t0.33366\n",
      "  valid accuracy:\t0.86630+/-0.00000\n",
      "  valid auc-roc:\t0.92975+/-0.00000\n",
      "  valid auc-pr:\t\t0.92605+/-0.00229\n",
      "saving model parameters to: ../results/test/original_model_bells_best.pickle\n",
      "Epoch 39 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.34000 -- accuracy=86.56%  \n",
      "  valid loss:\t\t0.33570\n",
      "  valid accuracy:\t0.86609+/-0.00000\n",
      "  valid auc-roc:\t0.92960+/-0.00000\n",
      "  valid auc-pr:\t\t0.92580+/-0.00217\n",
      "Epoch 40 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.33995 -- accuracy=86.58%  \n",
      "  valid loss:\t\t0.33436\n",
      "  valid accuracy:\t0.86618+/-0.00000\n",
      "  valid auc-roc:\t0.92980+/-0.00000\n",
      "  valid auc-pr:\t\t0.92615+/-0.00218\n",
      "Epoch 41 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.33969 -- accuracy=86.60%  \n",
      "  valid loss:\t\t0.33474\n",
      "  valid accuracy:\t0.86630+/-0.00000\n",
      "  valid auc-roc:\t0.92953+/-0.00000\n",
      "  valid auc-pr:\t\t0.92578+/-0.00230\n",
      "Epoch 42 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.33970 -- accuracy=86.59%  \n",
      "  valid loss:\t\t0.33387\n",
      "  valid accuracy:\t0.86648+/-0.00000\n",
      "  valid auc-roc:\t0.92983+/-0.00000\n",
      "  valid auc-pr:\t\t0.92608+/-0.00235\n",
      "Epoch 43 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.33952 -- accuracy=86.62%  \n",
      "  valid loss:\t\t0.33530\n",
      "  valid accuracy:\t0.86597+/-0.00000\n",
      "  valid auc-roc:\t0.92993+/-0.00000\n",
      "  valid auc-pr:\t\t0.92623+/-0.00213\n",
      "Epoch 44 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.33972 -- accuracy=86.62%  \n",
      "  valid loss:\t\t0.33486\n",
      "  valid accuracy:\t0.86623+/-0.00000\n",
      "  valid auc-roc:\t0.92962+/-0.00000\n",
      "  valid auc-pr:\t\t0.92582+/-0.00224\n",
      "Epoch 45 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.33937 -- accuracy=86.61%  \n",
      "  valid loss:\t\t0.33628\n",
      "  valid accuracy:\t0.86551+/-0.00000\n",
      "  valid auc-roc:\t0.92981+/-0.00000\n",
      "  valid auc-pr:\t\t0.92614+/-0.00220\n",
      "Epoch 46 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.33923 -- accuracy=86.61%  \n",
      "  valid loss:\t\t0.33351\n",
      "  valid accuracy:\t0.86632+/-0.00000\n",
      "  valid auc-roc:\t0.92989+/-0.00000\n",
      "  valid auc-pr:\t\t0.92622+/-0.00215\n",
      "saving model parameters to: ../results/test/original_model_bells_best.pickle\n",
      "Epoch 47 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.33938 -- accuracy=86.63%  \n",
      "  valid loss:\t\t0.33391\n",
      "  valid accuracy:\t0.86635+/-0.00000\n",
      "  valid auc-roc:\t0.92984+/-0.00000\n",
      "  valid auc-pr:\t\t0.92614+/-0.00217\n",
      "Epoch 48 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.33912 -- accuracy=86.63%  \n",
      "  valid loss:\t\t0.33600\n",
      "  valid accuracy:\t0.86638+/-0.00000\n",
      "  valid auc-roc:\t0.92969+/-0.00000\n",
      "  valid auc-pr:\t\t0.92597+/-0.00208\n",
      "Epoch 49 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.33954 -- accuracy=86.61%  \n",
      "  valid loss:\t\t0.33342\n",
      "  valid accuracy:\t0.86643+/-0.00000\n",
      "  valid auc-roc:\t0.92997+/-0.00000\n",
      "  valid auc-pr:\t\t0.92624+/-0.00214\n",
      "saving model parameters to: ../results/test/original_model_bells_best.pickle\n",
      "Epoch 50 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.33929 -- accuracy=86.61%  \n",
      "  valid loss:\t\t0.33691\n",
      "  valid accuracy:\t0.86619+/-0.00000\n",
      "  valid auc-roc:\t0.92992+/-0.00000\n",
      "  valid auc-pr:\t\t0.92614+/-0.00220\n",
      "Epoch 51 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.33906 -- accuracy=86.64%  \n",
      "  valid loss:\t\t0.33513\n",
      "  valid accuracy:\t0.86576+/-0.00000\n",
      "  valid auc-roc:\t0.92972+/-0.00000\n",
      "  valid auc-pr:\t\t0.92607+/-0.00202\n",
      "Epoch 52 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.33932 -- accuracy=86.59%  \n",
      "  valid loss:\t\t0.33320\n",
      "  valid accuracy:\t0.86666+/-0.00000\n",
      "  valid auc-roc:\t0.93007+/-0.00000\n",
      "  valid auc-pr:\t\t0.92646+/-0.00192\n",
      "saving model parameters to: ../results/test/original_model_bells_best.pickle\n",
      "Epoch 53 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.33908 -- accuracy=86.63%  \n",
      "  valid loss:\t\t0.33367\n",
      "  valid accuracy:\t0.86627+/-0.00000\n",
      "  valid auc-roc:\t0.92989+/-0.00000\n",
      "  valid auc-pr:\t\t0.92613+/-0.00210\n",
      "Epoch 54 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.33936 -- accuracy=86.61%  \n",
      "  valid loss:\t\t0.33399\n",
      "  valid accuracy:\t0.86648+/-0.00000\n",
      "  valid auc-roc:\t0.93005+/-0.00000\n",
      "  valid auc-pr:\t\t0.92631+/-0.00197\n",
      "Epoch 55 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.33898 -- accuracy=86.61%  \n",
      "  valid loss:\t\t0.33573\n",
      "  valid accuracy:\t0.86651+/-0.00000\n",
      "  valid auc-roc:\t0.92994+/-0.00000\n",
      "  valid auc-pr:\t\t0.92620+/-0.00224\n",
      "Epoch 56 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.33897 -- accuracy=86.62%  \n",
      "  valid loss:\t\t0.33355\n",
      "  valid accuracy:\t0.86654+/-0.00000\n",
      "  valid auc-roc:\t0.92998+/-0.00000\n",
      "  valid auc-pr:\t\t0.92627+/-0.00220\n",
      "Epoch 57 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.33893 -- accuracy=86.63%  \n",
      "  valid loss:\t\t0.33594\n",
      "  valid accuracy:\t0.86663+/-0.00000\n",
      "  valid auc-roc:\t0.93031+/-0.00000\n",
      "  valid auc-pr:\t\t0.92668+/-0.00198\n",
      "Epoch 58 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.33875 -- accuracy=86.66%  \n",
      "  valid loss:\t\t0.33767\n",
      "  valid accuracy:\t0.86567+/-0.00000\n",
      "  valid auc-roc:\t0.93009+/-0.00000\n",
      "  valid auc-pr:\t\t0.92645+/-0.00181\n",
      "Epoch 59 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.33889 -- accuracy=86.61%  \n",
      "  valid loss:\t\t0.33445\n",
      "  valid accuracy:\t0.86630+/-0.00000\n",
      "  valid auc-roc:\t0.92996+/-0.00000\n",
      "  valid auc-pr:\t\t0.92640+/-0.00199\n",
      "Epoch 60 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.33872 -- accuracy=86.63%  \n",
      "  valid loss:\t\t0.33287\n",
      "  valid accuracy:\t0.86606+/-0.00000\n",
      "  valid auc-roc:\t0.93023+/-0.00000\n",
      "  valid auc-pr:\t\t0.92672+/-0.00192\n",
      "saving model parameters to: ../results/test/original_model_bells_best.pickle\n",
      "Epoch 61 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.33887 -- accuracy=86.63%  \n",
      "  valid loss:\t\t0.33335\n",
      "  valid accuracy:\t0.86657+/-0.00000\n",
      "  valid auc-roc:\t0.93015+/-0.00000\n",
      "  valid auc-pr:\t\t0.92646+/-0.00216\n",
      "Epoch 62 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.33852 -- accuracy=86.65%  \n",
      "  valid loss:\t\t0.33372\n",
      "  valid accuracy:\t0.86648+/-0.00000\n",
      "  valid auc-roc:\t0.93021+/-0.00000\n",
      "  valid auc-pr:\t\t0.92663+/-0.00199\n",
      "Epoch 63 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.33845 -- accuracy=86.64%  \n",
      "  valid loss:\t\t0.33399\n",
      "  valid accuracy:\t0.86676+/-0.00000\n",
      "  valid auc-roc:\t0.93030+/-0.00000\n",
      "  valid auc-pr:\t\t0.92674+/-0.00192\n",
      "Epoch 64 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.33869 -- accuracy=86.63%  \n",
      "  valid loss:\t\t0.33416\n",
      "  valid accuracy:\t0.86652+/-0.00000\n",
      "  valid auc-roc:\t0.93000+/-0.00000\n",
      "  valid auc-pr:\t\t0.92621+/-0.00220\n",
      "Epoch 65 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.33865 -- accuracy=86.65%  \n",
      "  valid loss:\t\t0.33516\n",
      "  valid accuracy:\t0.86633+/-0.00000\n",
      "  valid auc-roc:\t0.93016+/-0.00000\n",
      "  valid auc-pr:\t\t0.92646+/-0.00193\n",
      "Epoch 66 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.33849 -- accuracy=86.63%  \n",
      "  valid loss:\t\t0.33471\n",
      "  valid accuracy:\t0.86655+/-0.00000\n",
      "  valid auc-roc:\t0.93004+/-0.00000\n",
      "  valid auc-pr:\t\t0.92630+/-0.00202\n",
      "Epoch 67 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.33838 -- accuracy=86.63%  \n",
      "  valid loss:\t\t0.33429\n",
      "  valid accuracy:\t0.86655+/-0.00000\n",
      "  valid auc-roc:\t0.93001+/-0.00000\n",
      "  valid auc-pr:\t\t0.92632+/-0.00217\n",
      "Epoch 68 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.33831 -- accuracy=86.65%  \n",
      "  valid loss:\t\t0.33297\n",
      "  valid accuracy:\t0.86649+/-0.00000\n",
      "  valid auc-roc:\t0.93021+/-0.00000\n",
      "  valid auc-pr:\t\t0.92656+/-0.00201\n",
      "Epoch 69 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.33818 -- accuracy=86.64%  \n",
      "  valid loss:\t\t0.33318\n",
      "  valid accuracy:\t0.86638+/-0.00000\n",
      "  valid auc-roc:\t0.93021+/-0.00000\n",
      "  valid auc-pr:\t\t0.92661+/-0.00196\n",
      "Epoch 70 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.33828 -- accuracy=86.64%  \n",
      "  valid loss:\t\t0.33407\n",
      "  valid accuracy:\t0.86645+/-0.00000\n",
      "  valid auc-roc:\t0.93020+/-0.00000\n",
      "  valid auc-pr:\t\t0.92657+/-0.00212\n",
      "Epoch 71 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.33873 -- accuracy=86.64%  \n",
      "  valid loss:\t\t0.33258\n",
      "  valid accuracy:\t0.86665+/-0.00000\n",
      "  valid auc-roc:\t0.93030+/-0.00000\n",
      "  valid auc-pr:\t\t0.92666+/-0.00202\n",
      "saving model parameters to: ../results/test/original_model_bells_best.pickle\n",
      "Epoch 72 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.33852 -- accuracy=86.64%  \n",
      "  valid loss:\t\t0.33576\n",
      "  valid accuracy:\t0.86617+/-0.00000\n",
      "  valid auc-roc:\t0.93000+/-0.00000\n",
      "  valid auc-pr:\t\t0.92635+/-0.00202\n",
      "Epoch 73 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.33826 -- accuracy=86.65%  \n",
      "  valid loss:\t\t0.33259\n",
      "  valid accuracy:\t0.86663+/-0.00000\n",
      "  valid auc-roc:\t0.93031+/-0.00000\n",
      "  valid auc-pr:\t\t0.92668+/-0.00192\n",
      "Epoch 74 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.33835 -- accuracy=86.65%  \n",
      "  valid loss:\t\t0.33218\n",
      "  valid accuracy:\t0.86690+/-0.00000\n",
      "  valid auc-roc:\t0.93046+/-0.00000\n",
      "  valid auc-pr:\t\t0.92686+/-0.00209\n",
      "saving model parameters to: ../results/test/original_model_bells_best.pickle\n",
      "Epoch 75 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.33827 -- accuracy=86.64%  \n",
      "  valid loss:\t\t0.33492\n",
      "  valid accuracy:\t0.86628+/-0.00000\n",
      "  valid auc-roc:\t0.93036+/-0.00000\n",
      "  valid auc-pr:\t\t0.92676+/-0.00207\n",
      "Epoch 76 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.33832 -- accuracy=86.63%  \n",
      "  valid loss:\t\t0.33299\n",
      "  valid accuracy:\t0.86668+/-0.00000\n",
      "  valid auc-roc:\t0.93052+/-0.00000\n",
      "  valid auc-pr:\t\t0.92700+/-0.00190\n",
      "Epoch 77 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.33836 -- accuracy=86.65%  \n",
      "  valid loss:\t\t0.33319\n",
      "  valid accuracy:\t0.86634+/-0.00000\n",
      "  valid auc-roc:\t0.93034+/-0.00000\n",
      "  valid auc-pr:\t\t0.92668+/-0.00210\n",
      "Epoch 78 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.33789 -- accuracy=86.66%  \n",
      "  valid loss:\t\t0.33261\n",
      "  valid accuracy:\t0.86674+/-0.00000\n",
      "  valid auc-roc:\t0.93057+/-0.00000\n",
      "  valid auc-pr:\t\t0.92707+/-0.00181\n",
      "Epoch 79 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.33774 -- accuracy=86.65%  \n",
      "  valid loss:\t\t0.33487\n",
      "  valid accuracy:\t0.86606+/-0.00000\n",
      "  valid auc-roc:\t0.93024+/-0.00000\n",
      "  valid auc-pr:\t\t0.92655+/-0.00196\n",
      "Epoch 80 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.33804 -- accuracy=86.67%  \n",
      "  valid loss:\t\t0.33344\n",
      "  valid accuracy:\t0.86673+/-0.00000\n",
      "  valid auc-roc:\t0.93037+/-0.00000\n",
      "  valid auc-pr:\t\t0.92676+/-0.00210\n",
      "Epoch 81 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.33800 -- accuracy=86.66%  \n",
      "  valid loss:\t\t0.33261\n",
      "  valid accuracy:\t0.86648+/-0.00000\n",
      "  valid auc-roc:\t0.93040+/-0.00000\n",
      "  valid auc-pr:\t\t0.92695+/-0.00186\n",
      "Epoch 82 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.33825 -- accuracy=86.66%  \n",
      "  valid loss:\t\t0.33589\n",
      "  valid accuracy:\t0.86590+/-0.00000\n",
      "  valid auc-roc:\t0.93024+/-0.00000\n",
      "  valid auc-pr:\t\t0.92661+/-0.00210\n",
      "Epoch 83 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.33799 -- accuracy=86.66%  \n",
      "  valid loss:\t\t0.33260\n",
      "  valid accuracy:\t0.86694+/-0.00000\n",
      "  valid auc-roc:\t0.93040+/-0.00000\n",
      "  valid auc-pr:\t\t0.92677+/-0.00206\n",
      "Epoch 84 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.33790 -- accuracy=86.68%  \n",
      "  valid loss:\t\t0.33315\n",
      "  valid accuracy:\t0.86678+/-0.00000\n",
      "  valid auc-roc:\t0.93035+/-0.00000\n",
      "  valid auc-pr:\t\t0.92676+/-0.00201\n",
      "Epoch 85 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.33779 -- accuracy=86.68%  \n",
      "  valid loss:\t\t0.33331\n",
      "  valid accuracy:\t0.86695+/-0.00000\n",
      "  valid auc-roc:\t0.93035+/-0.00000\n",
      "  valid auc-pr:\t\t0.92671+/-0.00199\n",
      "Patience ran out... Early stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<neuralnetwork.NeuralTrainer instance at 0x7f26ef154950>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train model\n",
    "fit.train_minibatch(nntrainer, data={'train': train, 'valid': valid}, \n",
    "                              batch_size=1000, num_epochs=500, patience=10, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  test  loss:\t\t0.33226\n",
      "  test  accuracy:\t0.86687+/-0.00000\n",
      "  test  auc-roc:\t0.93043+/-0.00000\n",
      "  test  auc-pr:\t\t0.92683+/-0.00208\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.33226152080699856"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nntrainer.set_best_parameters()\n",
    "\n",
    "# test model\n",
    "nntrainer.test_model(valid, batch_size=100, name=\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# modified network (wider + batch norm + dropout + prelu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "making directory: ../results/test/original_model_bells_whistles\n",
      "compiling model\n"
     ]
    }
   ],
   "source": [
    "def build_model(shape, num_labels):\n",
    "\n",
    "    # get model\n",
    "    input_var = T.tensor4('inputs')\n",
    "    target_var = T.dmatrix('targets')\n",
    "\n",
    "    net = {}\n",
    "    net['input'] = layers.InputLayer(input_var=input_var, shape=shape)\n",
    "    net['conv1'] = layers.Conv2DLayer(net['input'], num_filters=32, filter_size=(2, 5), stride=(1, 1),    # 1000\n",
    "                                        W=init.HeNormal(), b=None, nonlinearity=None, pad='valid')\n",
    "    net['conv1_norm'] = layers.BatchNormLayer(net['conv1'])\n",
    "    net['conv1_active'] = layers.ParametricRectifierLayer(net['conv1_norm'], alpha=init.Constant(0.25))\n",
    "    net['conv1_dropout'] = layers.DropoutLayer(net['conv1_active'], p=0.1)\n",
    "\n",
    "    net['conv2'] = layers.Conv2DLayer(net['conv1_dropout'], num_filters=64, filter_size=(2, 5), stride=(1, 1), # 18\n",
    "                                        W=init.HeNormal(), b=None, nonlinearity=None, pad='valid')\n",
    "    net['conv2_norm'] = layers.BatchNormLayer(net['conv2'])\n",
    "    net['conv2_active'] = layers.ParametricRectifierLayer(net['conv2_norm'], alpha=init.Constant(0.25))\n",
    "    net['conv2_pool'] = layers.MaxPool2DLayer(net['conv2_active'], pool_size=(1, 10), stride=(1, 10)) # 25\n",
    "    net['conv2_dropout'] = layers.DropoutLayer(net['conv2_pool'], p=0.1)\n",
    "\n",
    "    net['conv3'] = layers.Conv2DLayer(net['conv2_dropout'], num_filters=128, filter_size=(1, 1), stride=(1, 1), # 18\n",
    "                                        W=init.HeNormal(), b=None, nonlinearity=None, pad='valid')\n",
    "    net['conv3_norm'] = layers.BatchNormLayer(net['conv3'])\n",
    "    net['conv3_active'] = layers.ParametricRectifierLayer(net['conv3_norm'], alpha=init.Constant(0.25))\n",
    "    net['conv3_dropout'] = layers.DropoutLayer(net['conv3_active'], p=0.1)\n",
    "\n",
    "    net['dense1'] = layers.DenseLayer(net['conv3_dropout'], num_units=256, W=init.HeNormal(), \n",
    "                                     b=init.Constant(0.1), nonlinearity=None)\n",
    "    net['dense1_active'] = layers.ParametricRectifierLayer(net['dense1_norm'], alpha=init.Constant(0.25))\n",
    "    net['dense1_dropout'] = layers.DropoutLayer(net['dense1_active'], p=0.3)\n",
    "    \n",
    "    net['dense2'] = layers.DenseLayer(net['dense1_dropout'], num_units=num_labels, W=init.HeNormal(), \n",
    "                                     b=init.Constant(), nonlinearity=None)\n",
    "    net['output'] = layers.NonlinearityLayer(net['dense2'], nonlinearity=nonlinearities.sigmoid)\n",
    "    \n",
    "    # optimization parameters\n",
    "    optimization = {\"objective\": \"binary\",\n",
    "                    \"optimizer\": \"adam\",\n",
    "                    \"learning_rate\": 0.001, \n",
    "                    \"l2\": 1e-6\n",
    "                    }\n",
    "\n",
    "    return net, input_var, target_var, optimization\n",
    "\n",
    "# build network\n",
    "shape = (None, train[0].shape[1], train[0].shape[2], train[0].shape[3])\n",
    "num_labels = train[1].shape[1]\n",
    "net, input_var, target_var, optimization = build_model(shape, num_labels)\n",
    "\n",
    "# build neural network class\n",
    "nnmodel = NeuralNet(net, input_var, target_var)\n",
    "#nnmodel.inspect_layers()\n",
    "\n",
    "# set output file paths\n",
    "resultspath = utils.make_directory('../results', 'test')\n",
    "output_name = 'original_model_bells_whistles'\n",
    "filepath = os.path.join(resultspath, output_name)\n",
    "nntrainer = NeuralTrainer(nnmodel, optimization, save='best', filepath=filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.37656 -- accuracy=85.38%  \n",
      "  valid loss:\t\t0.35316\n",
      "  valid accuracy:\t0.86072+/-0.00000\n",
      "  valid auc-roc:\t0.92105+/-0.00000\n",
      "  valid auc-pr:\t\t0.91483+/-0.00416\n",
      "saving model parameters to: ../results/test/original_model_bells_whistles_best.pickle\n",
      "Epoch 2 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.36055 -- accuracy=86.04%  \n",
      "  valid loss:\t\t0.34587\n",
      "  valid accuracy:\t0.86301+/-0.00000\n",
      "  valid auc-roc:\t0.92435+/-0.00000\n",
      "  valid auc-pr:\t\t0.91946+/-0.00375\n",
      "saving model parameters to: ../results/test/original_model_bells_whistles_best.pickle\n",
      "Epoch 3 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.35643 -- accuracy=86.19%  \n",
      "  valid loss:\t\t0.34308\n",
      "  valid accuracy:\t0.86351+/-0.00000\n",
      "  valid auc-roc:\t0.92540+/-0.00000\n",
      "  valid auc-pr:\t\t0.92085+/-0.00323\n",
      "saving model parameters to: ../results/test/original_model_bells_whistles_best.pickle\n",
      "Epoch 4 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.35397 -- accuracy=86.28%  \n",
      "  valid loss:\t\t0.34174\n",
      "  valid accuracy:\t0.86451+/-0.00000\n",
      "  valid auc-roc:\t0.92669+/-0.00000\n",
      "  valid auc-pr:\t\t0.92234+/-0.00314\n",
      "saving model parameters to: ../results/test/original_model_bells_whistles_best.pickle\n",
      "Epoch 5 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.35208 -- accuracy=86.34%  \n",
      "  valid loss:\t\t0.33864\n",
      "  valid accuracy:\t0.86525+/-0.00000\n",
      "  valid auc-roc:\t0.92741+/-0.00000\n",
      "  valid auc-pr:\t\t0.92344+/-0.00264\n",
      "saving model parameters to: ../results/test/original_model_bells_whistles_best.pickle\n",
      "Epoch 6 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.35057 -- accuracy=86.42%  \n",
      "  valid loss:\t\t0.33811\n",
      "  valid accuracy:\t0.86487+/-0.00000\n",
      "  valid auc-roc:\t0.92781+/-0.00000\n",
      "  valid auc-pr:\t\t0.92374+/-0.00318\n",
      "saving model parameters to: ../results/test/original_model_bells_whistles_best.pickle\n",
      "Epoch 7 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.35011 -- accuracy=86.45%  \n",
      "  valid loss:\t\t0.33849\n",
      "  valid accuracy:\t0.86541+/-0.00000\n",
      "  valid auc-roc:\t0.92862+/-0.00000\n",
      "  valid auc-pr:\t\t0.92500+/-0.00251\n",
      "Epoch 8 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.34891 -- accuracy=86.43%  \n",
      "  valid loss:\t\t0.33727\n",
      "  valid accuracy:\t0.86558+/-0.00000\n",
      "  valid auc-roc:\t0.92799+/-0.00000\n",
      "  valid auc-pr:\t\t0.92374+/-0.00339\n",
      "saving model parameters to: ../results/test/original_model_bells_whistles_best.pickle\n",
      "Epoch 9 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.34829 -- accuracy=86.47%  \n",
      "  valid loss:\t\t0.33549\n",
      "  valid accuracy:\t0.86597+/-0.00000\n",
      "  valid auc-roc:\t0.92918+/-0.00000\n",
      "  valid auc-pr:\t\t0.92553+/-0.00248\n",
      "saving model parameters to: ../results/test/original_model_bells_whistles_best.pickle\n",
      "Epoch 10 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.34819 -- accuracy=86.49%  \n",
      "  valid loss:\t\t0.33552\n",
      "  valid accuracy:\t0.86590+/-0.00000\n",
      "  valid auc-roc:\t0.92886+/-0.00000\n",
      "  valid auc-pr:\t\t0.92505+/-0.00216\n",
      "Epoch 11 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.34762 -- accuracy=86.50%  \n",
      "  valid loss:\t\t0.33683\n",
      "  valid accuracy:\t0.86572+/-0.00000\n",
      "  valid auc-roc:\t0.92957+/-0.00000\n",
      "  valid auc-pr:\t\t0.92599+/-0.00209\n",
      "Epoch 12 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.34728 -- accuracy=86.51%  \n",
      "  valid loss:\t\t0.33394\n",
      "  valid accuracy:\t0.86673+/-0.00000\n",
      "  valid auc-roc:\t0.92965+/-0.00000\n",
      "  valid auc-pr:\t\t0.92606+/-0.00222\n",
      "saving model parameters to: ../results/test/original_model_bells_whistles_best.pickle\n",
      "Epoch 13 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.34723 -- accuracy=86.53%  \n",
      "  valid loss:\t\t0.33553\n",
      "  valid accuracy:\t0.86624+/-0.00000\n",
      "  valid auc-roc:\t0.93012+/-0.00000\n",
      "  valid auc-pr:\t\t0.92667+/-0.00168\n",
      "Epoch 14 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.34685 -- accuracy=86.52%  \n",
      "  valid loss:\t\t0.33488\n",
      "  valid accuracy:\t0.86578+/-0.00000\n",
      "  valid auc-roc:\t0.92992+/-0.00000\n",
      "  valid auc-pr:\t\t0.92651+/-0.00191\n",
      "Epoch 15 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.34661 -- accuracy=86.56%  \n",
      "  valid loss:\t\t0.33456\n",
      "  valid accuracy:\t0.86643+/-0.00000\n",
      "  valid auc-roc:\t0.93009+/-0.00000\n",
      "  valid auc-pr:\t\t0.92656+/-0.00164\n",
      "Epoch 16 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.34666 -- accuracy=86.56%  \n",
      "  valid loss:\t\t0.33522\n",
      "  valid accuracy:\t0.86640+/-0.00000\n",
      "  valid auc-roc:\t0.93014+/-0.00000\n",
      "  valid auc-pr:\t\t0.92668+/-0.00161\n",
      "Epoch 17 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.34624 -- accuracy=86.55%  \n",
      "  valid loss:\t\t0.33311\n",
      "  valid accuracy:\t0.86620+/-0.00000\n",
      "  valid auc-roc:\t0.93013+/-0.00000\n",
      "  valid auc-pr:\t\t0.92671+/-0.00165\n",
      "saving model parameters to: ../results/test/original_model_bells_whistles_best.pickle\n",
      "Epoch 18 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.34597 -- accuracy=86.60%  \n",
      "  valid loss:\t\t0.33232\n",
      "  valid accuracy:\t0.86668+/-0.00000\n",
      "  valid auc-roc:\t0.93051+/-0.00000\n",
      "  valid auc-pr:\t\t0.92722+/-0.00153\n",
      "saving model parameters to: ../results/test/original_model_bells_whistles_best.pickle\n",
      "Epoch 19 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.34595 -- accuracy=86.60%  \n",
      "  valid loss:\t\t0.33566\n",
      "  valid accuracy:\t0.86590+/-0.00000\n",
      "  valid auc-roc:\t0.93017+/-0.00000\n",
      "  valid auc-pr:\t\t0.92687+/-0.00168\n",
      "Epoch 20 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.34570 -- accuracy=86.59%  \n",
      "  valid loss:\t\t0.33448\n",
      "  valid accuracy:\t0.86585+/-0.00000\n",
      "  valid auc-roc:\t0.93009+/-0.00000\n",
      "  valid auc-pr:\t\t0.92676+/-0.00168\n",
      "Epoch 21 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.34561 -- accuracy=86.58%  \n",
      "  valid loss:\t\t0.33296\n",
      "  valid accuracy:\t0.86687+/-0.00000\n",
      "  valid auc-roc:\t0.93045+/-0.00000\n",
      "  valid auc-pr:\t\t0.92705+/-0.00172\n",
      "Epoch 22 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.34506 -- accuracy=86.59%  \n",
      "  valid loss:\t\t0.33217\n",
      "  valid accuracy:\t0.86658+/-0.00000\n",
      "  valid auc-roc:\t0.93069+/-0.00000\n",
      "  valid auc-pr:\t\t0.92741+/-0.00174\n",
      "saving model parameters to: ../results/test/original_model_bells_whistles_best.pickle\n",
      "Epoch 23 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.34524 -- accuracy=86.61%  \n",
      "  valid loss:\t\t0.33524\n",
      "  valid accuracy:\t0.86635+/-0.00000\n",
      "  valid auc-roc:\t0.93097+/-0.00000\n",
      "  valid auc-pr:\t\t0.92767+/-0.00126\n",
      "Epoch 24 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.34530 -- accuracy=86.63%  \n",
      "  valid loss:\t\t0.33311\n",
      "  valid accuracy:\t0.86632+/-0.00000\n",
      "  valid auc-roc:\t0.93037+/-0.00000\n",
      "  valid auc-pr:\t\t0.92687+/-0.00121\n",
      "Epoch 25 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.34520 -- accuracy=86.61%  \n",
      "  valid loss:\t\t0.33411\n",
      "  valid accuracy:\t0.86612+/-0.00000\n",
      "  valid auc-roc:\t0.93113+/-0.00000\n",
      "  valid auc-pr:\t\t0.92798+/-0.00122\n",
      "Epoch 26 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.34495 -- accuracy=86.60%  \n",
      "  valid loss:\t\t0.33209\n",
      "  valid accuracy:\t0.86687+/-0.00000\n",
      "  valid auc-roc:\t0.93100+/-0.00000\n",
      "  valid auc-pr:\t\t0.92771+/-0.00139\n",
      "saving model parameters to: ../results/test/original_model_bells_whistles_best.pickle\n",
      "Epoch 27 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.34525 -- accuracy=86.60%  \n",
      "  valid loss:\t\t0.33134\n",
      "  valid accuracy:\t0.86666+/-0.00000\n",
      "  valid auc-roc:\t0.93105+/-0.00000\n",
      "  valid auc-pr:\t\t0.92785+/-0.00129\n",
      "saving model parameters to: ../results/test/original_model_bells_whistles_best.pickle\n",
      "Epoch 28 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.34487 -- accuracy=86.60%  \n",
      "  valid loss:\t\t0.33081\n",
      "  valid accuracy:\t0.86735+/-0.00000\n",
      "  valid auc-roc:\t0.93143+/-0.00000\n",
      "  valid auc-pr:\t\t0.92827+/-0.00119\n",
      "saving model parameters to: ../results/test/original_model_bells_whistles_best.pickle\n",
      "Epoch 29 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.34479 -- accuracy=86.62%  \n",
      "  valid loss:\t\t0.33205\n",
      "  valid accuracy:\t0.86623+/-0.00000\n",
      "  valid auc-roc:\t0.93072+/-0.00000\n",
      "  valid auc-pr:\t\t0.92749+/-0.00150\n",
      "Epoch 30 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.34469 -- accuracy=86.64%  \n",
      "  valid loss:\t\t0.33741\n",
      "  valid accuracy:\t0.86645+/-0.00000\n",
      "  valid auc-roc:\t0.93043+/-0.00000\n",
      "  valid auc-pr:\t\t0.92714+/-0.00151\n",
      "Epoch 31 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.34452 -- accuracy=86.66%  \n",
      "  valid loss:\t\t0.33175\n",
      "  valid accuracy:\t0.86670+/-0.00000\n",
      "  valid auc-roc:\t0.93100+/-0.00000\n",
      "  valid auc-pr:\t\t0.92770+/-0.00154\n",
      "Epoch 32 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.34484 -- accuracy=86.63%  \n",
      "  valid loss:\t\t0.33313\n",
      "  valid accuracy:\t0.86721+/-0.00000\n",
      "  valid auc-roc:\t0.93176+/-0.00000\n",
      "  valid auc-pr:\t\t0.92858+/-0.00108\n",
      "Epoch 33 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.34445 -- accuracy=86.65%  \n",
      "  valid loss:\t\t0.33256\n",
      "  valid accuracy:\t0.86646+/-0.00000\n",
      "  valid auc-roc:\t0.93078+/-0.00000\n",
      "  valid auc-pr:\t\t0.92749+/-0.00117\n",
      "Epoch 34 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.34423 -- accuracy=86.68%  \n",
      "  valid loss:\t\t0.33230\n",
      "  valid accuracy:\t0.86654+/-0.00000\n",
      "  valid auc-roc:\t0.93133+/-0.00000\n",
      "  valid auc-pr:\t\t0.92818+/-0.00065\n",
      "Epoch 35 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.34421 -- accuracy=86.64%  \n",
      "  valid loss:\t\t0.33367\n",
      "  valid accuracy:\t0.86667+/-0.00000\n",
      "  valid auc-roc:\t0.93117+/-0.00000\n",
      "  valid auc-pr:\t\t0.92799+/-0.00106\n",
      "Epoch 36 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.34421 -- accuracy=86.66%  \n",
      "  valid loss:\t\t0.33282\n",
      "  valid accuracy:\t0.86601+/-0.00000\n",
      "  valid auc-roc:\t0.93141+/-0.00000\n",
      "  valid auc-pr:\t\t0.92816+/-0.00100\n",
      "Epoch 37 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.34414 -- accuracy=86.69%  \n",
      "  valid loss:\t\t0.33278\n",
      "  valid accuracy:\t0.86643+/-0.00000\n",
      "  valid auc-roc:\t0.93066+/-0.00000\n",
      "  valid auc-pr:\t\t0.92749+/-0.00134\n",
      "Epoch 38 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.34427 -- accuracy=86.67%  \n",
      "  valid loss:\t\t0.33060\n",
      "  valid accuracy:\t0.86697+/-0.00000\n",
      "  valid auc-roc:\t0.93161+/-0.00000\n",
      "  valid auc-pr:\t\t0.92851+/-0.00101\n",
      "saving model parameters to: ../results/test/original_model_bells_whistles_best.pickle\n",
      "Epoch 39 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.34407 -- accuracy=86.66%  \n",
      "  valid loss:\t\t0.33254\n",
      "  valid accuracy:\t0.86631+/-0.00000\n",
      "  valid auc-roc:\t0.93143+/-0.00000\n",
      "  valid auc-pr:\t\t0.92831+/-0.00084\n",
      "Epoch 40 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.34424 -- accuracy=86.66%  \n",
      "  valid loss:\t\t0.33157\n",
      "  valid accuracy:\t0.86680+/-0.00000\n",
      "  valid auc-roc:\t0.93151+/-0.00000\n",
      "  valid auc-pr:\t\t0.92840+/-0.00061\n",
      "Epoch 41 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.34383 -- accuracy=86.71%  \n",
      "  valid loss:\t\t0.33111\n",
      "  valid accuracy:\t0.86689+/-0.00000\n",
      "  valid auc-roc:\t0.93167+/-0.00000\n",
      "  valid auc-pr:\t\t0.92851+/-0.00089\n",
      "Epoch 42 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.34384 -- accuracy=86.66%  \n",
      "  valid loss:\t\t0.33195\n",
      "  valid accuracy:\t0.86667+/-0.00000\n",
      "  valid auc-roc:\t0.93153+/-0.00000\n",
      "  valid auc-pr:\t\t0.92848+/-0.00076\n",
      "Epoch 43 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.34390 -- accuracy=86.68%  \n",
      "  valid loss:\t\t0.32901\n",
      "  valid accuracy:\t0.86730+/-0.00000\n",
      "  valid auc-roc:\t0.93208+/-0.00000\n",
      "  valid auc-pr:\t\t0.92913+/-0.00068\n",
      "saving model parameters to: ../results/test/original_model_bells_whistles_best.pickle\n",
      "Epoch 44 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.34403 -- accuracy=86.67%  \n",
      "  valid loss:\t\t0.33308\n",
      "  valid accuracy:\t0.86626+/-0.00000\n",
      "  valid auc-roc:\t0.93153+/-0.00000\n",
      "  valid auc-pr:\t\t0.92855+/-0.00082\n",
      "Epoch 45 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.34390 -- accuracy=86.64%  \n",
      "  valid loss:\t\t0.32977\n",
      "  valid accuracy:\t0.86717+/-0.00000\n",
      "  valid auc-roc:\t0.93214+/-0.00000\n",
      "  valid auc-pr:\t\t0.92908+/-0.00055\n",
      "Epoch 46 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.34382 -- accuracy=86.68%  \n",
      "  valid loss:\t\t0.33005\n",
      "  valid accuracy:\t0.86722+/-0.00000\n",
      "  valid auc-roc:\t0.93208+/-0.00000\n",
      "  valid auc-pr:\t\t0.92903+/-0.00062\n",
      "Epoch 47 out of 500 \n",
      "[=========                     ] 28.4% -- time=142s -- loss=0.34090 -- accuracy=86.86%  "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-e7e9d29872a9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# train model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m fit.train_minibatch(nntrainer, data={'train': train, 'valid': valid}, \n\u001b[1;32m----> 3\u001b[1;33m                               batch_size=100, num_epochs=500, patience=10, verbose=1)\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;31m# train model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m fit.train_minibatch(nntrainer, data={'train': train, 'valid': valid}, \n",
      "\u001b[1;32m/home/peter/Code/deepomics/train.pyc\u001b[0m in \u001b[0;36mtrain_minibatch\u001b[1;34m(nntrainer, data, batch_size, num_epochs, patience, verbose, shuffle)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m                 \u001b[1;31m# training set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m                 \u001b[0mtrain_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnntrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m                 \u001b[0mnntrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'train'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/peter/Code/deepomics/neuralnetwork.pyc\u001b[0m in \u001b[0;36mtrain_step\u001b[1;34m(self, train, batch_size, verbose, shuffle)\u001b[0m\n\u001b[0;32m    221\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_batches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m                         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 223\u001b[1;33m                         \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    224\u001b[0m                         \u001b[0mvalue\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_metric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m                         \u001b[0mperformance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/peter/Theano/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    864\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    865\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 866\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[1;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    867\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    868\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/peter/Theano/theano/gof/op.pyc\u001b[0m in \u001b[0;36mrval\u001b[1;34m(p, i, o, n)\u001b[0m\n\u001b[0;32m    863\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mparams\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNoParams\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    864\u001b[0m             \u001b[1;31m# default arguments are stored in the closure of `rval`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 865\u001b[1;33m             \u001b[1;32mdef\u001b[0m \u001b[0mrval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode_input_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode_output_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    866\u001b[0m                 \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    867\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train model\n",
    "fit.train_minibatch(nntrainer, data={'train': train, 'valid': valid}, \n",
    "                              batch_size=100, num_epochs=10, patience=0, verbose=1)\n",
    "# train model\n",
    "nnmodel = NeuralNet(net, input_var, target_var)\n",
    "nntrainer = NeuralTrainer(nnmodel, optimization, save='best', filepath=filepath)\n",
    "nntrainer.set_best_parameters()\n",
    "fit.train_minibatch(nntrainer, data={'train': train, 'valid': valid}, \n",
    "                              batch_size=500, num_epochs=10, patience=0, verbose=1)\n",
    "\n",
    "nnmodel = NeuralNet(net, input_var, target_var)\n",
    "nntrainer = NeuralTrainer(nnmodel, optimization, save='best', filepath=filepath)\n",
    "nntrainer.set_best_parameters()\n",
    "fit.train_minibatch(nntrainer, data={'train': train, 'valid': valid}, \n",
    "                              batch_size=1000, num_epochs=5, patience=0, verbose=1)\n",
    "\n",
    "nnmodel = NeuralNet(net, input_var, target_var)\n",
    "nntrainer = NeuralTrainer(nnmodel, optimization, save='best', filepath=filepath)\n",
    "nntrainer.set_best_parameters()\n",
    "fit.train_minibatch(nntrainer, data={'train': train, 'valid': valid}, \n",
    "                              batch_size=1500, num_epochs=5, patience=0, verbose=1)\n",
    "\n",
    "nnmodel = NeuralNet(net, input_var, target_var)\n",
    "nntrainer = NeuralTrainer(nnmodel, optimization, save='best', filepath=filepath)\n",
    "nntrainer.set_best_parameters()\n",
    "fit.train_minibatch(nntrainer, data={'train': train, 'valid': valid}, \n",
    "                              batch_size=2000, num_epochs=5, patience=0, verbose=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  test  loss:\t\t0.32901\n",
      "  test  accuracy:\t0.86730+/-0.00000\n",
      "  test  auc-roc:\t0.93208+/-0.00000\n",
      "  test  auc-pr:\t\t0.92913+/-0.00068\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.32900719022581171"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nntrainer.set_best_parameters()\n",
    "\n",
    "# test model\n",
    "nntrainer.test_model(valid, batch_size=100, name=\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# normal residual model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compiling model\n"
     ]
    }
   ],
   "source": [
    "def build_model(shape, num_labels):\n",
    "    def residual_block(net, last_layer, name, filter_size, nonlinearity=nonlinearities.rectify):\n",
    "        # original residual unit\n",
    "        shape = layers.get_output_shape(net[last_layer])\n",
    "        num_filters = shape[1]\n",
    "\n",
    "        net[name+'_1resid'] = layers.Conv2DLayer(net[last_layer], num_filters=num_filters, filter_size=filter_size, stride=(1, 1),    # 1000\n",
    "                         W=init.HeNormal(), b=None, nonlinearity=None, pad='same')\n",
    "        net[name+'_1resid_norm'] = layers.BatchNormLayer(net[name+'_1resid'])\n",
    "        net[name+'_1resid_active'] = layers.NonlinearityLayer(net[name+'_1resid_norm'], nonlinearity=nonlinearity)\n",
    "\n",
    "        net[name+'_1resid_dropout'] = layers.DropoutLayer(net[name+'_1resid_active'], p=0.1)\n",
    "\n",
    "        # bottleneck residual layer\n",
    "        net[name+'_2resid'] = layers.Conv2DLayer(net[name+'_1resid_dropout'], num_filters=num_filters, filter_size=filter_size, stride=(1, 1),    # 1000\n",
    "                         W=init.HeNormal(), b=None, nonlinearity=None, pad='same')\n",
    "        net[name+'_2resid_norm'] = layers.BatchNormLayer(net[name+'_2resid'])\n",
    "\n",
    "        # combine input with residuals\n",
    "        net[name+'_residual'] = layers.ElemwiseSumLayer([net[last_layer], net[name+'_2resid_norm']])\n",
    "        net[name+'_resid'] = layers.NonlinearityLayer(net[name+'_residual'], nonlinearity=nonlinearity)\n",
    "\n",
    "        return net\n",
    "\n",
    "    def residual_block2(net, last_layer, name, nonlinearity=nonlinearities.rectify):\n",
    "        # original residual unit\n",
    "        shape = layers.get_output_shape(net[last_layer])\n",
    "        num_units = shape[1]\n",
    "\n",
    "        net[name+'_1resid'] = layers.DenseLayer(net[last_layer], num_units=num_units, W=init.HeNormal(), b=None, nonlinearity=None)\n",
    "        net[name+'_1resid_norm'] = layers.BatchNormLayer(net[name+'_1resid'])\n",
    "        net[name+'_1resid_active'] = layers.NonlinearityLayer(net[name+'_1resid_norm'], nonlinearity=nonlinearity)\n",
    "\n",
    "        net[name+'_1resid_dropout'] = layers.DropoutLayer(net[name+'_1resid_active'], p=0.1)\n",
    "\n",
    "        # bottleneck residual layer\n",
    "        net[name+'_2resid'] = layers.DenseLayer(net[name+'_1resid_dropout'], num_units=num_units, W=init.HeNormal(), b=None, nonlinearity=None)\n",
    "        net[name+'_2resid_norm'] = layers.BatchNormLayer(net[name+'_2resid'])\n",
    "\n",
    "        # combine input with residuals\n",
    "        net[name+'_residual'] = layers.ElemwiseSumLayer([net[last_layer], net[name+'_2resid_norm']])\n",
    "        net[name+'_resid'] = layers.NonlinearityLayer(net[name+'_residual'], nonlinearity=nonlinearity)\n",
    "\n",
    "        return net\n",
    "\n",
    "    # get model\n",
    "    input_var = T.tensor4('inputs')\n",
    "    target_var = T.dmatrix('targets')\n",
    "\n",
    "    net = {}\n",
    "    net['input'] = layers.InputLayer(input_var=input_var, shape=shape)\n",
    "    net['conv1'] = layers.Conv2DLayer(net['input'], num_filters=18, filter_size=(2, 5), stride=(1, 1),    # 1000\n",
    "                                        W=init.HeNormal(), b=None, nonlinearity=None, pad='valid')\n",
    "    net['conv1_norm'] = layers.BatchNormLayer(net['conv1'])\n",
    "    net['conv1_active'] = layers.NonlinearityLayer(net['conv1_norm'], nonlinearity=nonlinearities.leaky_rectify)\n",
    "    net['conv1_dropout1'] = layers.DropoutLayer(net['conv1_active'], p=0.1)\n",
    "    net = residual_block(net, 'conv1_dropout1', 'conv1_2', filter_size=(3,5), nonlinearity=nonlinearities.leaky_rectify)\n",
    "    net['conv1_dropout'] = layers.DropoutLayer(net['conv1_2_resid'], p=0.1)\n",
    "\n",
    "    net['conv2'] = layers.Conv2DLayer(net['conv1_dropout'], num_filters=40, filter_size=(2, 5), stride=(1, 1), # 18\n",
    "                                        W=init.HeNormal(), b=None, nonlinearity=None, pad='valid')\n",
    "    net['conv2_norm'] = layers.BatchNormLayer(net['conv2'])\n",
    "    net['conv2_active'] = layers.NonlinearityLayer(net['conv2_norm'], nonlinearity=nonlinearities.leaky_rectify)\n",
    "    net['conv2_dropout1'] = layers.DropoutLayer(net['conv2_active'], p=0.1)\n",
    "    net = residual_block(net, 'conv2_dropout1', 'conv2_2', filter_size=(1,5), nonlinearity=nonlinearities.leaky_rectify)\n",
    "    net['conv2_pool'] = layers.MaxPool2DLayer(net['conv2_2_resid'], pool_size=(1, 10), stride=(1, 10)) # 25\n",
    "    net['conv2_dropout'] = layers.DropoutLayer(net['conv2_pool'], p=0.1)\n",
    "\n",
    "    net['conv3'] = layers.Conv2DLayer(net['conv2_dropout'], num_filters=15, filter_size=(1, 1), stride=(1, 1), # 18\n",
    "                                        W=init.HeNormal(), b=None, nonlinearity=None, pad='valid')\n",
    "    net['conv3_norm'] = layers.BatchNormLayer(net['conv3'])\n",
    "    net['conv3_active'] = layers.NonlinearityLayer(net['conv3_norm'], nonlinearity=nonlinearities.leaky_rectify)\n",
    "    net['conv3_dropout'] = layers.DropoutLayer(net['conv3_active'], p=0.1)\n",
    "\n",
    "    net['dense1'] = layers.DenseLayer(net['conv3_dropout'], num_units=100, W=init.HeNormal(), \n",
    "                                     b=None, nonlinearity=None)\n",
    "    net['dense1_norm'] = layers.BatchNormLayer(net['dense1'])    \n",
    "    net['dense1_active'] = layers.NonlinearityLayer(net['dense1_norm'], nonlinearity=nonlinearities.leaky_rectify)\n",
    "    net['dense1_dropout1'] = layers.DropoutLayer(net['dense1_active'], p=0.1)\n",
    "    net = residual_block2(net, 'dense1_dropout1', 'dense1_2', nonlinearity=nonlinearities.leaky_rectify)\n",
    "    net['dense1_dropout'] = layers.DropoutLayer(net['dense1_2_resid'], p=0.3)\n",
    "    \n",
    "    net['dense2'] = layers.DenseLayer(net['dense1_dropout'], num_units=num_labels, W=init.HeNormal(), \n",
    "                                     b=init.Constant(), nonlinearity=None)\n",
    "    net['output'] = layers.NonlinearityLayer(net['dense2'], nonlinearity=nonlinearities.sigmoid)\n",
    "    \n",
    "    # optimization parameters\n",
    "    optimization = {\"objective\": \"binary\",\n",
    "                    \"optimizer\": \"adam\",\n",
    "                    \"learning_rate\": 0.001, \n",
    "                    \"l2\": 1e-6\n",
    "                    }\n",
    "\n",
    "    return net, input_var, target_var, optimization\n",
    "\n",
    "# build network\n",
    "shape = (None, train[0].shape[1], train[0].shape[2], train[0].shape[3])\n",
    "num_labels = train[1].shape[1]\n",
    "net, input_var, target_var, optimization = build_model(shape, num_labels)\n",
    "\n",
    "# build neural network class\n",
    "nnmodel = NeuralNet(net, input_var, target_var)\n",
    "#nnmodel.inspect_layers()\n",
    "\n",
    "# set output file paths\n",
    "resultspath = utils.make_directory('../results', 'deepomics')\n",
    "output_name = 'original_model_residual'\n",
    "filepath = os.path.join(resultspath, output_name)\n",
    "nntrainer = NeuralTrainer(nnmodel, optimization, save='best', filepath=filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 out of 10 \n",
      "[=====                         ] 15.9% -- time=317s -- loss=0.33416 -- accuracy=86.87%  "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-7d382093f1be>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mnntrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_best_parameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m fit.train_minibatch(nntrainer, data={'train': train, 'valid': valid}, \n\u001b[1;32m----> 4\u001b[1;33m                               batch_size=100, num_epochs=10, patience=0, verbose=1)\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;31m# train model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mnnmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNeuralNet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_var\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_var\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/peter/Code/deepomics/train.pyc\u001b[0m in \u001b[0;36mtrain_minibatch\u001b[1;34m(nntrainer, data, batch_size, num_epochs, patience, verbose, shuffle)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m                 \u001b[1;31m# training set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m                 \u001b[0mtrain_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnntrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m                 \u001b[0mnntrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'train'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/peter/Code/deepomics/neuralnetwork.pyc\u001b[0m in \u001b[0;36mtrain_step\u001b[1;34m(self, train, batch_size, verbose, shuffle)\u001b[0m\n\u001b[0;32m    221\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_batches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m                         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 223\u001b[1;33m                         \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    224\u001b[0m                         \u001b[0mvalue\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_metric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m                         \u001b[0mperformance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/peter/Theano/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    864\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    865\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 866\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[1;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    867\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    868\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/peter/Theano/theano/gof/op.pyc\u001b[0m in \u001b[0;36mrval\u001b[1;34m(p, i, o, n)\u001b[0m\n\u001b[0;32m    863\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mparams\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNoParams\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    864\u001b[0m             \u001b[1;31m# default arguments are stored in the closure of `rval`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 865\u001b[1;33m             \u001b[1;32mdef\u001b[0m \u001b[0mrval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode_input_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode_output_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    866\u001b[0m                 \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    867\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train model\n",
    "nntrainer.set_best_parameters()\n",
    "fit.train_minibatch(nntrainer, data={'train': train, 'valid': valid}, \n",
    "                              batch_size=100, num_epochs=10, patience=0, verbose=1)\n",
    "# train model\n",
    "nnmodel = NeuralNet(net, input_var, target_var)\n",
    "nntrainer = NeuralTrainer(nnmodel, optimization, save='best', filepath=filepath)\n",
    "nntrainer.set_best_parameters()\n",
    "fit.train_minibatch(nntrainer, data={'train': train, 'valid': valid}, \n",
    "                              batch_size=500, num_epochs=10, patience=0, verbose=1)\n",
    "\n",
    "nnmodel = NeuralNet(net, input_var, target_var)\n",
    "nntrainer = NeuralTrainer(nnmodel, optimization, save='best', filepath=filepath)\n",
    "nntrainer.set_best_parameters()\n",
    "fit.train_minibatch(nntrainer, data={'train': train, 'valid': valid}, \n",
    "                              batch_size=1000, num_epochs=5, patience=0, verbose=1)\n",
    "\n",
    "nnmodel = NeuralNet(net, input_var, target_var)\n",
    "nntrainer = NeuralTrainer(nnmodel, optimization, save='best', filepath=filepath)\n",
    "nntrainer.set_best_parameters()\n",
    "fit.train_minibatch(nntrainer, data={'train': train, 'valid': valid}, \n",
    "                              batch_size=1500, num_epochs=5, patience=0, verbose=1)\n",
    "\n",
    "nnmodel = NeuralNet(net, input_var, target_var)\n",
    "nntrainer = NeuralTrainer(nnmodel, optimization, save='best', filepath=filepath)\n",
    "nntrainer.set_best_parameters()\n",
    "fit.train_minibatch(nntrainer, data={'train': train, 'valid': valid}, \n",
    "                              batch_size=2000, num_epochs=5, patience=0, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  test  loss:\t\t0.32277\n",
      "  test  accuracy:\t0.86929+/-0.00000\n",
      "  test  auc-roc:\t0.93541+/-0.00000\n",
      "  test  auc-pr:\t\t0.93271+/-0.00030\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.32277447251302466"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nntrainer.set_best_parameters()\n",
    "\n",
    "# test model\n",
    "nntrainer.test_model(valid, batch_size=100, name=\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# residual model (modified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compiling model\n"
     ]
    }
   ],
   "source": [
    "def build_model(shape, num_labels):\n",
    "    def residual_block(net, last_layer, name, filter_size, nonlinearity=nonlinearities.rectify):\n",
    "        # original residual unit\n",
    "        shape = layers.get_output_shape(net[last_layer])\n",
    "        num_filters = shape[1]\n",
    "\n",
    "        net[name+'_1resid'] = layers.Conv2DLayer(net[last_layer], num_filters=num_filters, filter_size=filter_size, stride=(1, 1),    # 1000\n",
    "                         W=init.HeNormal(), b=None, nonlinearity=None, pad='same')\n",
    "        net[name+'_1resid_norm'] = layers.BatchNormLayer(net[name+'_1resid'])\n",
    "        net[name+'_1resid_active'] = layers.ParametricRectifierLayer(net[name+'_1resid_norm'], alpha=init.Constant(0.25))\n",
    "            \n",
    "        net[name+'_1resid_dropout'] = layers.DropoutLayer(net[name+'_1resid_active'], p=0.1)\n",
    "\n",
    "        # bottleneck residual layer\n",
    "        net[name+'_2resid'] = layers.Conv2DLayer(net[name+'_1resid_dropout'], num_filters=num_filters, filter_size=filter_size, stride=(1, 1),    # 1000\n",
    "                         W=init.HeNormal(), b=None, nonlinearity=None, pad='same')\n",
    "        net[name+'_2resid_norm'] = layers.BatchNormLayer(net[name+'_2resid'])\n",
    "\n",
    "        # combine input with residuals\n",
    "        net[name+'_residual'] = layers.ElemwiseSumLayer([net[last_layer], net[name+'_2resid_norm']])\n",
    "        net[name+'_resid'] = layers.ParametricRectifierLayer(net[name+'_residual'], alpha=init.Constant(0.25))\n",
    "\n",
    "        return net\n",
    "    \n",
    "    def residual_block2(net, last_layer, name, nonlinearity=nonlinearities.rectify):\n",
    "        # original residual unit\n",
    "        shape = layers.get_output_shape(net[last_layer])\n",
    "        num_units = shape[1]\n",
    "\n",
    "        net[name+'_1resid'] = layers.DenseLayer(net[last_layer], num_units=num_units, W=init.HeNormal(), b=None, nonlinearity=None)\n",
    "        net[name+'_1resid_norm'] = layers.BatchNormLayer(net[name+'_1resid'])\n",
    "        net[name+'_1resid_active'] = layers.ParametricRectifierLayer(net[name+'_1resid_norm'], alpha=init.Constant(0.25))\n",
    "\n",
    "        net[name+'_1resid_dropout'] = layers.DropoutLayer(net[name+'_1resid_active'], p=0.1)\n",
    "\n",
    "        # bottleneck residual layer\n",
    "        net[name+'_2resid'] = layers.DenseLayer(net[name+'_1resid_dropout'], num_units=num_units, W=init.HeNormal(), b=None, nonlinearity=None)\n",
    "        net[name+'_2resid_norm'] = layers.BatchNormLayer(net[name+'_2resid'])\n",
    "\n",
    "        # combine input with residuals\n",
    "        net[name+'_residual'] = layers.ElemwiseSumLayer([net[last_layer], net[name+'_2resid_norm']])\n",
    "        net[name+'_resid'] = layers.ParametricRectifierLayer(net[name+'_residual'], alpha=init.Constant(0.25))\n",
    "\n",
    "        return net\n",
    "\n",
    "    # get model\n",
    "    input_var = T.tensor4('inputs')\n",
    "    target_var = T.dmatrix('targets')\n",
    "\n",
    "    net = {}\n",
    "    net['input'] = layers.InputLayer(input_var=input_var, shape=shape)\n",
    "    net['conv1'] = layers.Conv2DLayer(net['input'], num_filters=32, filter_size=(2, 5), stride=(1, 1),    # 325\n",
    "                                        W=init.HeNormal(), b=None, nonlinearity=None, pad='valid')\n",
    "    net['conv1_norm'] = layers.BatchNormLayer(net['conv1'])\n",
    "    net['conv1_active'] = layers.ParametricRectifierLayer(net['conv1_norm'], alpha=init.Constant(0.25))\n",
    "    net['conv1_dropout1'] = layers.DropoutLayer(net['conv1_active'], p=0.1)\n",
    "    net = residual_block(net, 'conv1_dropout1', 'conv1_2', filter_size=(3, 5), nonlinearity=nonlinearities.leaky_rectify)\n",
    "    net['conv1_dropout'] = layers.DropoutLayer(net['conv1_2_resid'], p=0.1)\n",
    "\n",
    "    net['conv2'] = layers.Conv2DLayer(net['conv1_dropout'], num_filters=64, filter_size=(2, 5), stride=(1, 1), # 60\n",
    "                                        W=init.HeNormal(), b=None, nonlinearity=None, pad='valid')\n",
    "    net['conv2_norm'] = layers.BatchNormLayer(net['conv2'])\n",
    "    net['conv2_active'] = layers.ParametricRectifierLayer(net['conv2_norm'], alpha=init.Constant(0.25))\n",
    "    net['conv2_dropout1'] = layers.DropoutLayer(net['conv2_active'], p=0.1)\n",
    "    net = residual_block(net, 'conv2_dropout1', 'conv2_2', filter_size=(1, 5), nonlinearity=nonlinearities.leaky_rectify)\n",
    "    net['conv2_pool'] = layers.MaxPool2DLayer(net['conv2_2_resid'], pool_size=(1, 10), stride=(1, 10)) # 12\n",
    "    net['conv2_dropout'] = layers.DropoutLayer(net['conv2_pool'], p=0.1)\n",
    "\n",
    "    net['conv3'] = layers.Conv2DLayer(net['conv2_dropout'], num_filters=128, filter_size=(1, 1), stride=(1, 1), # 9\n",
    "                                        W=init.HeNormal(), b=None, nonlinearity=None, pad='valid')\n",
    "    net['conv3_norm'] = layers.BatchNormLayer(net['conv3'])\n",
    "    net['conv3_active'] = layers.ParametricRectifierLayer(net['conv3_norm'], alpha=init.Constant(0.25))\n",
    "    net['conv3_dropout'] = layers.DropoutLayer(net['conv3_active'], p=0.1)\n",
    "    \n",
    "    net['dense1'] = layers.DenseLayer(net['conv3_dropout'], num_units=256, W=init.HeNormal(), \n",
    "                                     b=None, nonlinearity=None)\n",
    "    net['dense1_norm'] = layers.BatchNormLayer(net['dense1'])    \n",
    "    net['dense1_active'] = layers.ParametricRectifierLayer(net['dense1_norm'], alpha=init.Constant(0.25))\n",
    "    net['dense1_dropout1'] = layers.DropoutLayer(net['dense1_active'], p=0.1)\n",
    "    net = residual_block2(net, 'dense1_dropout1', 'dense1_2', nonlinearity=nonlinearities.leaky_rectify)\n",
    "    net['dense1_dropout'] = layers.DropoutLayer(net['dense1_2_resid'], p=0.3)\n",
    "        \n",
    "    net['dense2'] = layers.DenseLayer(net['dense1_dropout'], num_units=num_labels, W=init.HeNormal(), \n",
    "                                     b=init.Constant(), nonlinearity=None)\n",
    "    net['output'] = layers.NonlinearityLayer(net['dense2'], nonlinearity=nonlinearities.sigmoid)\n",
    "        \n",
    "    # optimization parameters\n",
    "    optimization = {\"objective\": \"binary\",\n",
    "                    \"optimizer\": \"adam\",\n",
    "                    \"learning_rate\": 0.0003, \n",
    "                    \"l2\": 1e-5\n",
    "                    }\n",
    "\n",
    "    return net, input_var, target_var, optimization\n",
    "\n",
    "# build network\n",
    "shape = (None, train[0].shape[1], train[0].shape[2], train[0].shape[3])\n",
    "num_labels = train[1].shape[1]\n",
    "net, input_var, target_var, optimization = build_model(shape, num_labels)\n",
    "\n",
    "# build neural network class\n",
    "nnmodel = NeuralNet(net, input_var, target_var)\n",
    "#nnmodel.inspect_layers()\n",
    "\n",
    "# set output file paths\n",
    "resultspath = utils.make_directory('../results', 'deepomics')\n",
    "output_name = '1D_model_resid'\n",
    "filepath = os.path.join(resultspath, output_name)\n",
    "nntrainer = NeuralTrainer(nnmodel, optimization, save='best', filepath=filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train model\n",
    "nntrainer.set_best_parameters()\n",
    "fit.train_minibatch(nntrainer, data={'train': train, 'valid': valid}, \n",
    "                              batch_size=100, num_epochs=10, patience=0, verbose=1)\n",
    "\n",
    "# train model\n",
    "nnmodel = NeuralNet(net, input_var, target_var)\n",
    "nntrainer = NeuralTrainer(nnmodel, optimization, save='best', filepath=filepath)\n",
    "nntrainer.set_best_parameters()\n",
    "fit.train_minibatch(nntrainer, data={'train': train, 'valid': valid}, \n",
    "                              batch_size=500, num_epochs=10, patience=0, verbose=1)\n",
    "\n",
    "nnmodel = NeuralNet(net, input_var, target_var)\n",
    "nntrainer = NeuralTrainer(nnmodel, optimization, save='best', filepath=filepath)\n",
    "nntrainer.set_best_parameters()\n",
    "fit.train_minibatch(nntrainer, data={'train': train, 'valid': valid}, \n",
    "                              batch_size=1000, num_epochs=5, patience=0, verbose=1)\n",
    "\n",
    "nnmodel = NeuralNet(net, input_var, target_var)\n",
    "nntrainer = NeuralTrainer(nnmodel, optimization, save='best', filepath=filepath)\n",
    "nntrainer.set_best_parameters()\n",
    "fit.train_minibatch(nntrainer, data={'train': train, 'valid': valid}, \n",
    "                              batch_size=1500, num_epochs=5, patience=0, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compiling model\n",
      "Epoch 1 out of 10 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.32797 -- accuracy=87.23%  \n",
      "  valid loss:\t\t0.31416\n",
      "  valid accuracy:\t0.87172+/-0.00000\n",
      "  valid auc-roc:\t0.93945+/-0.00000\n",
      "  valid auc-pr:\t\t0.93715+/-0.00218\n",
      "saving model parameters to: ../results/test/1D_model_resid_best.pickle\n",
      "Epoch 2 out of 10 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.32450 -- accuracy=87.33%  \n",
      "  valid loss:\t\t0.31575\n",
      "  valid accuracy:\t0.87252+/-0.00000\n",
      "  valid auc-roc:\t0.93963+/-0.00000\n",
      "  valid auc-pr:\t\t0.93724+/-0.00214\n",
      "Epoch 3 out of 10 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.32301 -- accuracy=87.39%  \n",
      "  valid loss:\t\t0.31205\n",
      "  valid accuracy:\t0.87268+/-0.00000\n",
      "  valid auc-roc:\t0.94037+/-0.00000\n",
      "  valid auc-pr:\t\t0.93814+/-0.00254\n",
      "saving model parameters to: ../results/test/1D_model_resid_best.pickle\n",
      "Epoch 4 out of 10 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.32166 -- accuracy=87.42%  \n",
      "  valid loss:\t\t0.31246\n",
      "  valid accuracy:\t0.87315+/-0.00000\n",
      "  valid auc-roc:\t0.94044+/-0.00000\n",
      "  valid auc-pr:\t\t0.93819+/-0.00256\n",
      "Epoch 5 out of 10 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.32081 -- accuracy=87.44%  \n",
      "  valid loss:\t\t0.31423\n",
      "  valid accuracy:\t0.87284+/-0.00000\n",
      "  valid auc-roc:\t0.94077+/-0.00000\n",
      "  valid auc-pr:\t\t0.93857+/-0.00281\n",
      "Epoch 6 out of 10 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.31998 -- accuracy=87.50%  \n",
      "  valid loss:\t\t0.30944\n",
      "  valid accuracy:\t0.87386+/-0.00000\n",
      "  valid auc-roc:\t0.94101+/-0.00000\n",
      "  valid auc-pr:\t\t0.93879+/-0.00282\n",
      "saving model parameters to: ../results/test/1D_model_resid_best.pickle\n",
      "Epoch 7 out of 10 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.31912 -- accuracy=87.52%  \n",
      "  valid loss:\t\t0.32383\n",
      "  valid accuracy:\t0.87158+/-0.00000\n",
      "  valid auc-roc:\t0.94037+/-0.00000\n",
      "  valid auc-pr:\t\t0.93814+/-0.00265\n",
      "Epoch 8 out of 10 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.31856 -- accuracy=87.52%  \n",
      "  valid loss:\t\t0.30985\n",
      "  valid accuracy:\t0.87376+/-0.00000\n",
      "  valid auc-roc:\t0.94123+/-0.00000\n",
      "  valid auc-pr:\t\t0.93911+/-0.00312\n",
      "Epoch 9 out of 10 \n",
      "[=====================         ] 71.4% -- time=116s -- loss=0.31747 -- accuracy=87.58%  "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-2f0bed50d9bb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mnntrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_best_parameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m fit.train_minibatch(nntrainer, data={'train': train, 'valid': valid}, \n\u001b[1;32m----> 5\u001b[1;33m                               batch_size=1500, num_epochs=10, patience=5, verbose=1)\n\u001b[0m",
      "\u001b[1;32m/home/peter/Code/deepomics/train.pyc\u001b[0m in \u001b[0;36mtrain_minibatch\u001b[1;34m(nntrainer, data, batch_size, num_epochs, patience, verbose, shuffle)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m                 \u001b[1;31m# training set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m                 \u001b[0mtrain_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnntrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m                 \u001b[0mnntrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'train'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/peter/Code/deepomics/neuralnetwork.pyc\u001b[0m in \u001b[0;36mtrain_step\u001b[1;34m(self, train, batch_size, verbose, shuffle)\u001b[0m\n\u001b[0;32m    221\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_batches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m                         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 223\u001b[1;33m                         \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    224\u001b[0m                         \u001b[0mvalue\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_metric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m                         \u001b[0mperformance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/peter/Theano/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    864\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    865\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 866\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[1;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    867\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    868\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/peter/Theano/theano/gof/op.pyc\u001b[0m in \u001b[0;36mrval\u001b[1;34m(p, i, o, n)\u001b[0m\n\u001b[0;32m    863\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mparams\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNoParams\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    864\u001b[0m             \u001b[1;31m# default arguments are stored in the closure of `rval`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 865\u001b[1;33m             \u001b[1;32mdef\u001b[0m \u001b[0mrval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode_input_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode_output_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    866\u001b[0m                 \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    867\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nnmodel = NeuralNet(net, input_var, target_var)\n",
    "nntrainer = NeuralTrainer(nnmodel, optimization, save='best', filepath=filepath)\n",
    "nntrainer.set_best_parameters()\n",
    "fit.train_minibatch(nntrainer, data={'train': train, 'valid': valid}, \n",
    "                              batch_size=2000, num_epochs=10, patience=5, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 ms, sys: 8 ms, total: 12 ms\n",
      "Wall time: 9.56 ms\n"
     ]
    }
   ],
   "source": [
    "\n",
    "file_path = os.path.join(data_path,'valideval_dataset.hdf5')\n",
    "\n",
    "group_name = ['valid_data']\n",
    "dataset = h5py.File(file_path,'r')\n",
    "%time val_dat = np.array(dataset['/'+group_name[0]+'/vs_valid'])\n",
    "val_lbl = np.array(dataset['/'+group_name[0]+'/label_valid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14000"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 85, 170, 255, 340, 425, 510, 595, 680, 765, 850, 935, 1020, 1105, 1190]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range(0, val_dat.shape[1] - fragLen, startgap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ceil((val_dat.shape[1] - fragLen)/14.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "N=14\n",
    "fragLen=330\n",
    "\n",
    "avg_F = np.mean(val_dat,axis=0)\n",
    "\n",
    "startgap = np.ceil((val_dat.shape[1] - fragLen)/14.).astype('int')\n",
    "true_lbl = np.zeros((val_dat.shape[0]*val_dat.shape[0],), dtype='float32')\n",
    "pred_lbl = np.zeros((val_dat.shape[0]*val_dat.shape[0],), dtype='float32')\n",
    "    \n",
    "# Counter for the \"true_lbl\" array\n",
    "cnt_ = 0\n",
    "# Counter for the \"pred_lbl\" array\n",
    "cnt_u = 0\n",
    "for a in range(val_dat.shape[0]):\n",
    "    if a%100 == 0:\n",
    "        sys.stdout.write('\\r' + 'X'*(a//100))\n",
    "\n",
    "    # Create batch array to send thru network\n",
    "    im_eval = np.empty((N*val_dat.shape[0],3,fragLen,1), dtype='float32')\n",
    "\n",
    "    # Count the number of traces in each batch\n",
    "    cnt = 0\n",
    "\n",
    "    for b in range(val_dat.shape[0]):\n",
    "\n",
    "        for n in range(0, val_dat.shape[1] - fragLen, startgap):\n",
    "            try:\n",
    "                im_eval[cnt,:,:,0] = np.vstack((val_dat[a,n:n+fragLen],\n",
    "                                     val_dat[b,n:n+fragLen],\n",
    "                                     avg_F[n:n+fragLen]))\n",
    "            except:\n",
    "                from IPython.core.debugger import Tracer\n",
    "                Tracer()()\n",
    "\n",
    "            cnt += 1\n",
    "\n",
    "        # Keep track of the true labels\n",
    "        if val_lbl[a,b] == 1:\n",
    "            true_lbl[cnt_] = 1\n",
    "        else:\n",
    "            true_lbl[cnt_] = 0\n",
    "\n",
    "        cnt_ += 1\n",
    "\n",
    "    # Run batch through network\n",
    "    pred_stop = nnmodel.get_feature_maps(layer='output', X=im_eval.transpose([0,3,1,2]))\n",
    "\n",
    "    # Average output over each group of N traces\n",
    "    for u in range(0, len(pred_stop), N):\n",
    "        pred_lbl[cnt_u] = np.mean(pred_stop[u:u+N])\n",
    "        cnt_u += 1        \n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(true_lbl, pred_lbl)\n",
    "\n",
    "auc(fpr, tpr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  test  loss:\t\t0.30959\n",
      "  test  accuracy:\t0.87378+/-0.00000\n",
      "  test  auc-roc:\t0.94096+/-0.00000\n",
      "  test  auc-pr:\t\t0.93873+/-0.00285\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3095861364629392"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nntrainer.set_best_parameters()\n",
    "\n",
    "# test model\n",
    "nntrainer.test_model(valid, batch_size=100, name=\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1D models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1D architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compiling model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO (theano.gof.compilelock): Refreshing lock /home/peter/.theano/compiledir_Linux-4.4--generic-x86_64-with-debian-stretch-sid-x86_64-2.7.12-64/lock_dir/lock\n",
      "INFO:theano.gof.compilelock:Refreshing lock /home/peter/.theano/compiledir_Linux-4.4--generic-x86_64-with-debian-stretch-sid-x86_64-2.7.12-64/lock_dir/lock\n"
     ]
    }
   ],
   "source": [
    "def build_model(shape, num_labels):\n",
    "    def residual_block(net, last_layer, name, filter_size, nonlinearity=nonlinearities.rectify):\n",
    "        # original residual unit\n",
    "        shape = layers.get_output_shape(net[last_layer])\n",
    "        num_filters = shape[1]\n",
    "\n",
    "        net[name+'_1resid'] = layers.Conv2DLayer(net[last_layer], num_filters=num_filters, filter_size=filter_size, stride=(1, 1),    # 1000\n",
    "                         W=init.HeNormal(), b=None, nonlinearity=None, pad='same')\n",
    "        net[name+'_1resid_norm'] = layers.BatchNormLayer(net[name+'_1resid'])\n",
    "        net[name+'_1resid_active'] = layers.NonlinearityLayer(net[name+'_1resid_norm'], nonlinearity=nonlinearity)\n",
    "\n",
    "        net[name+'_1resid_dropout'] = layers.DropoutLayer(net[name+'_1resid_active'], p=0.1)\n",
    "\n",
    "        # bottleneck residual layer\n",
    "        net[name+'_2resid'] = layers.Conv2DLayer(net[name+'_1resid_dropout'], num_filters=num_filters, filter_size=filter_size, stride=(1, 1),    # 1000\n",
    "                         W=init.HeNormal(), b=None, nonlinearity=None, pad='same')\n",
    "        net[name+'_2resid_norm'] = layers.BatchNormLayer(net[name+'_2resid'])\n",
    "\n",
    "        # combine input with residuals\n",
    "        net[name+'_residual'] = layers.ElemwiseSumLayer([net[last_layer], net[name+'_2resid_norm']])\n",
    "        net[name+'_resid'] = layers.NonlinearityLayer(net[name+'_residual'], nonlinearity=nonlinearity)\n",
    "\n",
    "        return net\n",
    "\n",
    "    def residual_block2(net, last_layer, name, nonlinearity=nonlinearities.rectify):\n",
    "        # original residual unit\n",
    "        shape = layers.get_output_shape(net[last_layer])\n",
    "        num_units = shape[1]\n",
    "\n",
    "        net[name+'_1resid'] = layers.DenseLayer(net[last_layer], num_units=num_units, W=init.HeNormal(), b=None, nonlinearity=None)\n",
    "        net[name+'_1resid_norm'] = layers.BatchNormLayer(net[name+'_1resid'])\n",
    "        net[name+'_1resid_active'] = layers.NonlinearityLayer(net[name+'_1resid_norm'], nonlinearity=nonlinearity)\n",
    "\n",
    "        net[name+'_1resid_dropout'] = layers.DropoutLayer(net[name+'_1resid_active'], p=0.1)\n",
    "\n",
    "        # bottleneck residual layer\n",
    "        net[name+'_2resid'] = layers.DenseLayer(net[name+'_1resid_dropout'], num_units=num_units, W=init.HeNormal(), b=None, nonlinearity=None)\n",
    "        net[name+'_2resid_norm'] = layers.BatchNormLayer(net[name+'_2resid'])\n",
    "\n",
    "        # combine input with residuals\n",
    "        net[name+'_residual'] = layers.ElemwiseSumLayer([net[last_layer], net[name+'_2resid_norm']])\n",
    "        net[name+'_resid'] = layers.NonlinearityLayer(net[name+'_residual'], nonlinearity=nonlinearity)\n",
    "\n",
    "        return net\n",
    "\n",
    "    \n",
    "    # get model\n",
    "    input_var = T.tensor4('inputs')\n",
    "    target_var = T.dmatrix('targets')\n",
    "\n",
    "    net = {}\n",
    "    net['input'] = layers.InputLayer(input_var=input_var, shape=shape)\n",
    "    net['conv1'] = layers.Conv2DLayer(net['input'], num_filters=32, filter_size=(3, 11), stride=(1, 1),    # 320\n",
    "                                        W=init.HeNormal(), b=None, nonlinearity=None, pad='valid')\n",
    "    net['conv1_norm'] = layers.BatchNormLayer(net['conv1'])\n",
    "    net['conv1_active'] = layers.NonlinearityLayer(net['conv1_norm'], nonlinearity=nonlinearities.leaky_rectify)\n",
    "    net['conv1_dropout1'] = layers.DropoutLayer(net['conv1_active'], p=0.1)\n",
    "    net = residual_block(net, 'conv1_dropout1', 'conv1_2', filter_size=(1,5), nonlinearity=nonlinearities.leaky_rectify)\n",
    "    net['conv1_pool'] = layers.MaxPool2DLayer(net['conv1_2_resid'], pool_size=(1, 32), stride=(1, 32)) # 13\n",
    "    net['conv1_dropout'] = layers.DropoutLayer(net['conv1_pool'], p=0.1)\n",
    "\n",
    "    net['dense1'] = layers.DenseLayer(net['conv1_dropout'], num_units=128, W=init.HeNormal(), \n",
    "                                     b=None, nonlinearity=None)\n",
    "    net['dense1_norm'] = layers.BatchNormLayer(net['dense1'])    \n",
    "    net['dense1_active'] = layers.NonlinearityLayer(net['dense1_norm'], nonlinearity=nonlinearities.leaky_rectify)\n",
    "    net['dense1_dropout1'] = layers.DropoutLayer(net['dense1_active'], p=0.1)\n",
    "    net = residual_block2(net, 'dense1_dropout1', 'dense1_2', nonlinearity=nonlinearities.leaky_rectify)\n",
    "    net['dense1_dropout'] = layers.DropoutLayer(net['dense1_2_resid'], p=0.3)\n",
    "    \n",
    "    net['dense2'] = layers.DenseLayer(net['dense1_dropout'], num_units=num_labels, W=init.HeNormal(), \n",
    "                                     b=init.Constant(), nonlinearity=None)\n",
    "    net['output'] = layers.NonlinearityLayer(net['dense2'], nonlinearity=nonlinearities.sigmoid)\n",
    "    \n",
    "    # optimization parameters\n",
    "    optimization = {\"objective\": \"binary\",\n",
    "                    \"optimizer\": \"adam\",\n",
    "                    \"learning_rate\": 0.001, \n",
    "                    \"l2\": 1e-6\n",
    "                    }\n",
    "\n",
    "    return net, input_var, target_var, optimization\n",
    "\n",
    "# build network\n",
    "shape = (None, train[0].shape[1], train[0].shape[2], train[0].shape[3])\n",
    "num_labels = train[1].shape[1]\n",
    "net, input_var, target_var, optimization = build_model(shape, num_labels)\n",
    "\n",
    "# build neural network class\n",
    "nnmodel = NeuralNet(net, input_var, target_var)\n",
    "#nnmodel.inspect_layers()\n",
    "\n",
    "# set output file paths\n",
    "resultspath = utils.make_directory('../results', 'deepomics')\n",
    "output_name = '1d_version'\n",
    "filepath = os.path.join(resultspath, output_name)\n",
    "nntrainer = NeuralTrainer(nnmodel, optimization, save='best', filepath=filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 out of 10 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.34254 -- accuracy=86.56%  \n",
      "  valid loss:\t\t0.33890\n",
      "  valid accuracy:\t0.86542+/-0.00000\n",
      "  valid auc-roc:\t0.92866+/-0.00000\n",
      "  valid auc-pr:\t\t0.92491+/-0.00224\n",
      "saving model parameters to: ../results/test/1d_version_best.pickle\n",
      "Epoch 2 out of 10 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.34299 -- accuracy=86.58%  \n",
      "  valid loss:\t\t0.33836\n",
      "  valid accuracy:\t0.86514+/-0.00000\n",
      "  valid auc-roc:\t0.92846+/-0.00000\n",
      "  valid auc-pr:\t\t0.92417+/-0.00267\n",
      "saving model parameters to: ../results/test/1d_version_best.pickle\n",
      "Epoch 3 out of 10 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.34332 -- accuracy=86.57%  \n",
      "  valid loss:\t\t0.33682\n",
      "  valid accuracy:\t0.86581+/-0.00000\n",
      "  valid auc-roc:\t0.92914+/-0.00000\n",
      "  valid auc-pr:\t\t0.92489+/-0.00272\n",
      "saving model parameters to: ../results/test/1d_version_best.pickle\n",
      "Epoch 4 out of 10 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.34290 -- accuracy=86.58%  \n",
      "  valid loss:\t\t0.34078\n",
      "  valid accuracy:\t0.86392+/-0.00000\n",
      "  valid auc-roc:\t0.92820+/-0.00000\n",
      "  valid auc-pr:\t\t0.92393+/-0.00311\n",
      "Epoch 5 out of 10 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.34253 -- accuracy=86.62%  \n",
      "  valid loss:\t\t0.33484\n",
      "  valid accuracy:\t0.86681+/-0.00000\n",
      "  valid auc-roc:\t0.93004+/-0.00000\n",
      "  valid auc-pr:\t\t0.92628+/-0.00170\n",
      "saving model parameters to: ../results/test/1d_version_best.pickle\n",
      "Epoch 6 out of 10 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.34286 -- accuracy=86.60%  \n",
      "  valid loss:\t\t0.34330\n",
      "  valid accuracy:\t0.86345+/-0.00000\n",
      "  valid auc-roc:\t0.92652+/-0.00000\n",
      "  valid auc-pr:\t\t0.92016+/-0.00472\n",
      "Epoch 7 out of 10 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.34283 -- accuracy=86.62%  \n",
      "  valid loss:\t\t0.33573\n",
      "  valid accuracy:\t0.86601+/-0.00000\n",
      "  valid auc-roc:\t0.92975+/-0.00000\n",
      "  valid auc-pr:\t\t0.92603+/-0.00213\n",
      "Epoch 8 out of 10 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.34225 -- accuracy=86.62%  \n",
      "  valid loss:\t\t0.33630\n",
      "  valid accuracy:\t0.86559+/-0.00000\n",
      "  valid auc-roc:\t0.92898+/-0.00000\n",
      "  valid auc-pr:\t\t0.92469+/-0.00241\n",
      "Epoch 9 out of 10 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.34223 -- accuracy=86.64%  \n",
      "  valid loss:\t\t0.33874\n",
      "  valid accuracy:\t0.86522+/-0.00000\n",
      "  valid auc-roc:\t0.92896+/-0.00000\n",
      "  valid auc-pr:\t\t0.92427+/-0.00331\n",
      "Epoch 10 out of 10 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.34206 -- accuracy=86.63%  \n",
      "  valid loss:\t\t0.33350\n",
      "  valid accuracy:\t0.86722+/-0.00000\n",
      "  valid auc-roc:\t0.93012+/-0.00000\n",
      "  valid auc-pr:\t\t0.92640+/-0.00144\n",
      "saving model parameters to: ../results/test/1d_version_best.pickle\n",
      "compiling model\n",
      "Epoch 1 out of 10 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.33669 -- accuracy=86.81%  \n",
      "  valid loss:\t\t0.33052\n",
      "  valid accuracy:\t0.86758+/-0.00000\n",
      "  valid auc-roc:\t0.93149+/-0.00000\n",
      "  valid auc-pr:\t\t0.92809+/-0.00130\n",
      "saving model parameters to: ../results/test/1d_version_best.pickle\n",
      "Epoch 2 out of 10 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.33544 -- accuracy=86.83%  \n",
      "  valid loss:\t\t0.33022\n",
      "  valid accuracy:\t0.86811+/-0.00000\n",
      "  valid auc-roc:\t0.93197+/-0.00000\n",
      "  valid auc-pr:\t\t0.92875+/-0.00103\n",
      "saving model parameters to: ../results/test/1d_version_best.pickle\n",
      "Epoch 3 out of 10 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.33502 -- accuracy=86.84%  \n",
      "  valid loss:\t\t0.33073\n",
      "  valid accuracy:\t0.86717+/-0.00000\n",
      "  valid auc-roc:\t0.93215+/-0.00000\n",
      "  valid auc-pr:\t\t0.92895+/-0.00089\n",
      "Epoch 4 out of 10 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.33485 -- accuracy=86.84%  \n",
      "  valid loss:\t\t0.33110\n",
      "  valid accuracy:\t0.86769+/-0.00000\n",
      "  valid auc-roc:\t0.93181+/-0.00000\n",
      "  valid auc-pr:\t\t0.92857+/-0.00104\n",
      "Epoch 5 out of 10 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.33447 -- accuracy=86.87%  \n",
      "  valid loss:\t\t0.33078\n",
      "  valid accuracy:\t0.86697+/-0.00000\n",
      "  valid auc-roc:\t0.93164+/-0.00000\n",
      "  valid auc-pr:\t\t0.92830+/-0.00118\n",
      "Epoch 6 out of 10 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.33395 -- accuracy=86.85%  \n",
      "  valid loss:\t\t0.33030\n",
      "  valid accuracy:\t0.86739+/-0.00000\n",
      "  valid auc-roc:\t0.93212+/-0.00000\n",
      "  valid auc-pr:\t\t0.92882+/-0.00108\n",
      "Epoch 7 out of 10 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.33373 -- accuracy=86.89%  \n",
      "  valid loss:\t\t0.33056\n",
      "  valid accuracy:\t0.86845+/-0.00000\n",
      "  valid auc-roc:\t0.93243+/-0.00000\n",
      "  valid auc-pr:\t\t0.92926+/-0.00082\n",
      "Epoch 8 out of 10 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.33328 -- accuracy=86.89%  \n",
      "  valid loss:\t\t0.33083\n",
      "  valid accuracy:\t0.86741+/-0.00000\n",
      "  valid auc-roc:\t0.93186+/-0.00000\n",
      "  valid auc-pr:\t\t0.92858+/-0.00076\n",
      "Epoch 9 out of 10 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.33310 -- accuracy=86.90%  \n",
      "  valid loss:\t\t0.33119\n",
      "  valid accuracy:\t0.86769+/-0.00000\n",
      "  valid auc-roc:\t0.93210+/-0.00000\n",
      "  valid auc-pr:\t\t0.92887+/-0.00064\n",
      "Epoch 10 out of 10 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.33300 -- accuracy=86.89%  \n",
      "  valid loss:\t\t0.32929\n",
      "  valid accuracy:\t0.86803+/-0.00000\n",
      "  valid auc-roc:\t0.93221+/-0.00000\n",
      "  valid auc-pr:\t\t0.92896+/-0.00084\n",
      "saving model parameters to: ../results/test/1d_version_best.pickle\n",
      "compiling model\n",
      "Epoch 1 out of 5 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.33146 -- accuracy=86.93%  \n",
      "  valid loss:\t\t0.32863\n",
      "  valid accuracy:\t0.86814+/-0.00000\n",
      "  valid auc-roc:\t0.93237+/-0.00000\n",
      "  valid auc-pr:\t\t0.92915+/-0.00072\n",
      "saving model parameters to: ../results/test/1d_version_best.pickle\n",
      "Epoch 2 out of 5 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.33103 -- accuracy=86.95%  \n",
      "  valid loss:\t\t0.32917\n",
      "  valid accuracy:\t0.86787+/-0.00000\n",
      "  valid auc-roc:\t0.93268+/-0.00000\n",
      "  valid auc-pr:\t\t0.92954+/-0.00072\n",
      "Epoch 3 out of 5 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.33090 -- accuracy=86.95%  \n",
      "  valid loss:\t\t0.33108\n",
      "  valid accuracy:\t0.86738+/-0.00000\n",
      "  valid auc-roc:\t0.93251+/-0.00000\n",
      "  valid auc-pr:\t\t0.92919+/-0.00061\n",
      "Epoch 4 out of 5 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.33054 -- accuracy=86.96%  \n",
      "  valid loss:\t\t0.32980\n",
      "  valid accuracy:\t0.86811+/-0.00000\n",
      "  valid auc-roc:\t0.93230+/-0.00000\n",
      "  valid auc-pr:\t\t0.92912+/-0.00069\n",
      "Epoch 5 out of 5 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.33056 -- accuracy=86.99%  \n",
      "  valid loss:\t\t0.33030\n",
      "  valid accuracy:\t0.86772+/-0.00000\n",
      "  valid auc-roc:\t0.93221+/-0.00000\n",
      "  valid auc-pr:\t\t0.92896+/-0.00070\n",
      "compiling model\n",
      "Epoch 1 out of 5 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.33050 -- accuracy=87.01%  \n",
      "  valid loss:\t\t0.32825\n",
      "  valid accuracy:\t0.86821+/-0.00000\n",
      "  valid auc-roc:\t0.93260+/-0.00000\n",
      "  valid auc-pr:\t\t0.92933+/-0.00054\n",
      "saving model parameters to: ../results/test/1d_version_best.pickle\n",
      "Epoch 2 out of 5 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.33037 -- accuracy=86.96%  \n",
      "  valid loss:\t\t0.32933\n",
      "  valid accuracy:\t0.86791+/-0.00000\n",
      "  valid auc-roc:\t0.93250+/-0.00000\n",
      "  valid auc-pr:\t\t0.92932+/-0.00056\n",
      "Epoch 3 out of 5 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.33036 -- accuracy=86.99%  \n",
      "  valid loss:\t\t0.32999\n",
      "  valid accuracy:\t0.86786+/-0.00000\n",
      "  valid auc-roc:\t0.93264+/-0.00000\n",
      "  valid auc-pr:\t\t0.92943+/-0.00068\n",
      "Epoch 4 out of 5 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.32978 -- accuracy=86.98%  \n",
      "  valid loss:\t\t0.33134\n",
      "  valid accuracy:\t0.86778+/-0.00000\n",
      "  valid auc-roc:\t0.93238+/-0.00000\n",
      "  valid auc-pr:\t\t0.92919+/-0.00039\n",
      "Epoch 5 out of 5 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.32976 -- accuracy=87.02%  \n",
      "  valid loss:\t\t0.32844\n",
      "  valid accuracy:\t0.86806+/-0.00000\n",
      "  valid auc-roc:\t0.93272+/-0.00000\n",
      "  valid auc-pr:\t\t0.92958+/-0.00047\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<neuralnetwork.NeuralTrainer instance at 0x7f26dd99def0>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train model\n",
    "fit.train_minibatch(nntrainer, data={'train': train, 'valid': valid}, \n",
    "                              batch_size=100, num_epochs=10, patience=0, verbose=1)\n",
    "# train model\n",
    "nnmodel = NeuralNet(net, input_var, target_var)\n",
    "nntrainer = NeuralTrainer(nnmodel, optimization, save='best', filepath=filepath)\n",
    "nntrainer.set_best_parameters()\n",
    "fit.train_minibatch(nntrainer, data={'train': train, 'valid': valid}, \n",
    "                              batch_size=500, num_epochs=10, patience=0, verbose=1)\n",
    "\n",
    "nnmodel = NeuralNet(net, input_var, target_var)\n",
    "nntrainer = NeuralTrainer(nnmodel, optimization, save='best', filepath=filepath)\n",
    "nntrainer.set_best_parameters()\n",
    "fit.train_minibatch(nntrainer, data={'train': train, 'valid': valid}, \n",
    "                              batch_size=1000, num_epochs=5, patience=0, verbose=1)\n",
    "\n",
    "nnmodel = NeuralNet(net, input_var, target_var)\n",
    "nntrainer = NeuralTrainer(nnmodel, optimization, save='best', filepath=filepath)\n",
    "nntrainer.set_best_parameters()\n",
    "fit.train_minibatch(nntrainer, data={'train': train, 'valid': valid}, \n",
    "                              batch_size=1500, num_epochs=5, patience=0, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  test  loss:\t\t0.32840\n",
      "  test  accuracy:\t0.86813+/-0.00000\n",
      "  test  auc-roc:\t0.93255+/-0.00000\n",
      "  test  auc-pr:\t\t0.92928+/-0.00052\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.32840126553278232"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nntrainer.set_best_parameters()\n",
    "\n",
    "# test model\n",
    "nntrainer.test_model(valid, batch_size=100, name=\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1D residual model (modified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_model(shape, num_labels):\n",
    "    def residual_block(net, last_layer, name, filter_size, nonlinearity=nonlinearities.rectify):\n",
    "        # original residual unit\n",
    "        shape = layers.get_output_shape(net[last_layer])\n",
    "        num_filters = shape[1]\n",
    "\n",
    "        net[name+'_1resid'] = layers.Conv2DLayer(net[last_layer], num_filters=num_filters, filter_size=filter_size, stride=(1, 1),    # 1000\n",
    "                         W=init.HeNormal(), b=None, nonlinearity=None, pad='same')\n",
    "        net[name+'_1resid_norm'] = layers.BatchNormLayer(net[name+'_1resid'])\n",
    "        net[name+'_1resid_active'] = layers.NonlinearityLayer(net[name+'_1resid_norm'], nonlinearity=nonlinearity)\n",
    "\n",
    "        net[name+'_1resid_dropout'] = layers.DropoutLayer(net[name+'_1resid_active'], p=0.1)\n",
    "\n",
    "        # bottleneck residual layer\n",
    "        net[name+'_2resid'] = layers.Conv2DLayer(net[name+'_1resid_dropout'], num_filters=num_filters, filter_size=filter_size, stride=(1, 1),    # 1000\n",
    "                         W=init.HeNormal(), b=None, nonlinearity=None, pad='same')\n",
    "        net[name+'_2resid_norm'] = layers.BatchNormLayer(net[name+'_2resid'])\n",
    "\n",
    "        # combine input with residuals\n",
    "        net[name+'_residual'] = layers.ElemwiseSumLayer([net[last_layer], net[name+'_2resid_norm']])\n",
    "        net[name+'_resid'] = layers.NonlinearityLayer(net[name+'_residual'], nonlinearity=nonlinearity)\n",
    "\n",
    "        return net\n",
    "\n",
    "    \n",
    "    def residual_block2(net, last_layer, name, nonlinearity=nonlinearities.rectify):\n",
    "        # original residual unit\n",
    "        shape = layers.get_output_shape(net[last_layer])\n",
    "        num_units = shape[1]\n",
    "\n",
    "        net[name+'_1resid'] = layers.DenseLayer(net[last_layer], num_units=num_units, W=init.HeNormal(), b=None, nonlinearity=None)\n",
    "        net[name+'_1resid_norm'] = layers.BatchNormLayer(net[name+'_1resid'])\n",
    "        net[name+'_1resid_active'] = layers.NonlinearityLayer(net[name+'_1resid_norm'], nonlinearity=nonlinearity)\n",
    "\n",
    "        net[name+'_1resid_dropout'] = layers.DropoutLayer(net[name+'_1resid_active'], p=0.1)\n",
    "\n",
    "        # bottleneck residual layer\n",
    "        net[name+'_2resid'] = layers.DenseLayer(net[name+'_1resid_dropout'], num_units=num_units, W=init.HeNormal(), b=None, nonlinearity=None)\n",
    "        net[name+'_2resid_norm'] = layers.BatchNormLayer(net[name+'_2resid'])\n",
    "\n",
    "        # combine input with residuals\n",
    "        net[name+'_residual'] = layers.ElemwiseSumLayer([net[last_layer], net[name+'_2resid_norm']])\n",
    "        net[name+'_resid'] = layers.NonlinearityLayer(net[name+'_residual'], nonlinearity=nonlinearity)\n",
    "\n",
    "        return net\n",
    "\n",
    "\n",
    "    # get model\n",
    "    input_var = T.tensor4('inputs')\n",
    "    target_var = T.dmatrix('targets')\n",
    "\n",
    "    net = {}\n",
    "    net['input'] = layers.InputLayer(input_var=input_var, shape=shape) # 330\n",
    "    net['conv1'] = layers.Conv2DLayer(net['input'], num_filters=32, filter_size=(3, 7), stride=(1, 1), # 324\n",
    "                                        W=init.HeNormal(), b=None, nonlinearity=None, pad='valid')\n",
    "    net['conv1_norm'] = layers.BatchNormLayer(net['conv1'])\n",
    "    net['conv1_active'] = layers.NonlinearityLayer(net['conv1_norm'], nonlinearity=nonlinearities.leaky_rectify)\n",
    "    net['conv1_dropout1'] = layers.DropoutLayer(net['conv1_active'], p=0.1)\n",
    "    net = residual_block(net, 'conv1_dropout1', 'conv1_2', filter_size=(1,5), nonlinearity=nonlinearities.leaky_rectify)\n",
    "    net['conv1_pool'] = layers.MaxPool2DLayer(net['conv1_2_resid'], pool_size=(1, 12), stride=(1, 12)) # 27\n",
    "    net['conv1_dropout'] = layers.DropoutLayer(net['conv1_pool'], p=0.1)\n",
    "\n",
    "    net['conv2'] = layers.Conv2DLayer(net['conv1_dropout'], num_filters=64, filter_size=(1, 7), stride=(1, 1), # 21\n",
    "                                        W=init.HeNormal(), b=None, nonlinearity=None, pad='valid')\n",
    "    net['conv2_norm'] = layers.BatchNormLayer(net['conv2'])\n",
    "    net['conv2_active'] = layers.NonlinearityLayer(net['conv2_norm'], nonlinearity=nonlinearities.leaky_rectify)\n",
    "    net['conv2_dropout1'] = layers.DropoutLayer(net['conv2_active'], p=0.1)\n",
    "    net = residual_block(net, 'conv2_dropout1', 'conv2_2', filter_size=(1,5), nonlinearity=nonlinearities.leaky_rectify)\n",
    "    net['conv2_pool'] = layers.MaxPool2DLayer(net['conv2_2_resid'], pool_size=(1, 7), stride=(1, 7)) # 3\n",
    "    net['conv2_dropout'] = layers.DropoutLayer(net['conv2_pool'], p=0.1)\n",
    "\n",
    "    net['dense1'] = layers.DenseLayer(net['conv2_dropout'], num_units=128, W=init.HeNormal(), \n",
    "                                     b=None, nonlinearity=None)\n",
    "    net['dense1_norm'] = layers.BatchNormLayer(net['dense1'])    \n",
    "    net['dense1_active'] = layers.NonlinearityLayer(net['dense1_norm'], nonlinearity=nonlinearities.leaky_rectify)\n",
    "    net['dense1_dropout1'] = layers.DropoutLayer(net['dense1_active'], p=0.1)\n",
    "    net = residual_block2(net, 'dense1_dropout1', 'dense1_2', nonlinearity=nonlinearities.leaky_rectify)\n",
    "    net['dense1_dropout'] = layers.DropoutLayer(net['dense1_2_resid'], p=0.3\n",
    "    \n",
    "    net['dense2'] = layers.DenseLayer(net['dense1_dropout'], num_units=num_labels, W=init.HeNormal(), \n",
    "                                     b=init.Constant(), nonlinearity=None)\n",
    "    net['output'] = layers.NonlinearityLayer(net['dense2'], nonlinearity=nonlinearities.sigmoid)\n",
    "    \n",
    "    # optimization parameters\n",
    "    optimization = {\"objective\": \"binary\",\n",
    "                    \"optimizer\": \"adam\",\n",
    "                    \"learning_rate\": 0.001, \n",
    "                    \"l2\": 1e-6\n",
    "                    }\n",
    "\n",
    "    return net, input_var, target_var, optimization\n",
    "\n",
    "# build network\n",
    "shape = (None, train[0].shape[1], train[0].shape[2], train[0].shape[3])\n",
    "num_labels = train[1].shape[1]\n",
    "net, input_var, target_var, optimization = build_model(shape, num_labels)\n",
    "\n",
    "# build neural network class\n",
    "nnmodel = NeuralNet(net, input_var, target_var)\n",
    "#nnmodel.inspect_layers()\n",
    "\n",
    "# set output file paths\n",
    "resultspath = utils.make_directory('../results', 'test')\n",
    "output_name = '1D_model_resid'\n",
    "filepath = os.path.join(resultspath, output_name)\n",
    "nntrainer = NeuralTrainer(nnmodel, optimization, save='best', filepath=filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train model\n",
    "fit.train_minibatch(nntrainer, data={'train': train, 'valid': valid}, \n",
    "                              batch_size=100, num_epochs=10, patience=0, verbose=1)\n",
    "# train model\n",
    "nnmodel = NeuralNet(net, input_var, target_var)\n",
    "nntrainer = NeuralTrainer(nnmodel, optimization, save='best', filepath=filepath)\n",
    "nntrainer.set_best_parameters()\n",
    "fit.train_minibatch(nntrainer, data={'train': train, 'valid': valid}, \n",
    "                              batch_size=500, num_epochs=10, patience=0, verbose=1)\n",
    "\n",
    "nnmodel = NeuralNet(net, input_var, target_var)\n",
    "nntrainer = NeuralTrainer(nnmodel, optimization, save='best', filepath=filepath)\n",
    "nntrainer.set_best_parameters()\n",
    "fit.train_minibatch(nntrainer, data={'train': train, 'valid': valid}, \n",
    "                              batch_size=1000, num_epochs=5, patience=0, verbose=1)\n",
    "\n",
    "nnmodel = NeuralNet(net, input_var, target_var)\n",
    "nntrainer = NeuralTrainer(nnmodel, optimization, save='best', filepath=filepath)\n",
    "nntrainer.set_best_parameters()\n",
    "fit.train_minibatch(nntrainer, data={'train': train, 'valid': valid}, \n",
    "                              batch_size=1500, num_epochs=5, patience=0, verbose=1)\n",
    "\n",
    "nnmodel = NeuralNet(net, input_var, target_var)\n",
    "nntrainer = NeuralTrainer(nnmodel, optimization, save='best', filepath=filepath)\n",
    "nntrainer.set_best_parameters()\n",
    "fit.train_minibatch(nntrainer, data={'train': train, 'valid': valid}, \n",
    "                              batch_size=2000, num_epochs=5, patience=0, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nntrainer.set_best_parameters()\n",
    "\n",
    "# test model\n",
    "nntrainer.test_model(valid, batch_size=100, name=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
