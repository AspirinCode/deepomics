{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function \n",
    "import os, sys, h5py\n",
    "import numpy as np\n",
    "from six.moves import cPickle\n",
    "from collections import OrderedDict\n",
    "\n",
    "import tensorflow as tf\n",
    "sys.path.append('..')\n",
    "from tfomics import neuralnetwork as nn\n",
    "from tfomics import utils, fit, init, visualize, saliency\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading training data\n",
      "loading cross-validation data\n",
      "loading test data\n"
     ]
    }
   ],
   "source": [
    "def load_simulation(filepath):\n",
    "    # setup paths for file handling\n",
    "\n",
    "    trainmat = h5py.File(filepath, 'r')\n",
    "\n",
    "    print(\"loading training data\")\n",
    "    X_train = np.array(trainmat['X_train']).astype(np.float32)\n",
    "    y_train = np.array(trainmat['Y_train']).astype(np.float32)\n",
    "\n",
    "    print(\"loading cross-validation data\")\n",
    "    X_valid = np.array(trainmat['X_valid']).astype(np.float32)\n",
    "    y_valid = np.array(trainmat['Y_valid']).astype(np.int32)\n",
    "\n",
    "    print(\"loading test data\")\n",
    "    X_test = np.array(trainmat['X_test']).astype(np.float32)\n",
    "    y_test = np.array(trainmat['Y_test']).astype(np.int32)\n",
    "\n",
    "\n",
    "    X_train = np.expand_dims(X_train, axis=3).transpose([0,2,3,1])\n",
    "    X_valid = np.expand_dims(X_valid, axis=3).transpose([0,2,3,1])\n",
    "    X_test = np.expand_dims(X_test, axis=3).transpose([0,2,3,1])\n",
    "\n",
    "    return X_train, y_train, X_valid, y_valid, X_test, y_test\n",
    "\n",
    "\n",
    "# load data\n",
    "filename = 'Synthetic_TF_dataset_50000.h5'\n",
    "data_path = '../../real_gneomic_representations/data/synthetic_TF_dataset'\n",
    "file_path = os.path.join(data_path, filename)\n",
    "X_train, y_train, X_valid, y_valid, X_test, y_test = load_simulation(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def model(input_shape, output_shape):\n",
    "\n",
    "    # create model\n",
    "    layer1 = {'layer': 'input',\n",
    "            'input_shape': input_shape\n",
    "            }\n",
    "    layer2 = {'layer': 'conv1d', \n",
    "            'num_filters': 32,\n",
    "            'filter_size': 11,\n",
    "            'norm': 'batch',\n",
    "            'activation': 'relu',\n",
    "            'dropout': 0.1,\n",
    "            'padding': 'SAME',\n",
    "            'pool_size': 40,\n",
    "            }\n",
    "    layer3 = {'layer': 'conv1d', \n",
    "            'num_filters': 64,\n",
    "            'filter_size': 5,\n",
    "            'norm': 'batch',\n",
    "            'activation': 'relu',\n",
    "            'dropout': 0.2,\n",
    "            'padding': 'VALID',\n",
    "            }  \n",
    "    layer4 = {'layer': 'dense', \n",
    "            'num_units': output_shape[1],\n",
    "            'activation': 'sigmoid'\n",
    "            }\n",
    "\n",
    "    #from tfomics import build_network\n",
    "    model_layers = [layer1, layer2, layer3, layer4]\n",
    "    \n",
    "    # optimization parameters\n",
    "    optimization = {\"objective\": \"binary\",\n",
    "                  \"optimizer\": \"adam\",\n",
    "                  \"learning_rate\": 0.001, \n",
    "                  #\"l2\": 1e-6,\n",
    "                  #\"l1\": 0.1, \n",
    "                  }\n",
    "    return model_layers, optimization\n",
    "\n",
    "\n",
    "# get shapes\n",
    "num_data, height, width, dim = X_train.shape\n",
    "input_shape=[None, height, width, dim]\n",
    "output_shape = y_train.shape\n",
    "\n",
    "model_layers, optimization = model(input_shape, output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# set output file paths\n",
    "results_path = utils.make_directory(data_path, 'tmp')\n",
    "output_name = 'test'\n",
    "file_path = os.path.join(results_path, output_name)\n",
    "\n",
    "# build neural network class\n",
    "nnmodel = nn.NeuralNet()\n",
    "nnmodel.build_layers(model_layers, optimization)\n",
    "# nnmodel.inspect_layers()\n",
    "\n",
    "# compile neural trainer\n",
    "nntrainer = nn.NeuralTrainer(nnmodel, save='best', file_path=file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess = utils.initialize_session(nnmodel.placeholders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = {'inputs': X_train, 'targets': y_train}\n",
    "valid = {'inputs': X_valid, 'targets': y_valid}\n",
    "test = {'inputs': X_test, 'targets': y_test}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 out of 50 \n",
      "[==============                ] 45.1% -- time=23s -- loss=0.78306 -- accuracy=54.37%  "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-918b424336ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'valid'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'test'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m fit.train_minibatch(sess, nntrainer, data, batch_size=100, num_epochs=50, \n\u001b[0;32m----> 3\u001b[0;31m                       patience=20, verbose=2, shuffle=True, save_all=False)\n\u001b[0m",
      "\u001b[0;32m/Users/juliankimura/Google Drive/tensorflow/tfomics/tfomics/fit.py\u001b[0m in \u001b[0;36mtrain_minibatch\u001b[0;34m(sess, nntrainer, data, batch_size, num_epochs, patience, verbose, shuffle, save_all, save_epochs)\u001b[0m\n\u001b[1;32m     31\u001b[0m                                                                                         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                                                                                         \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \t\t\t\t\t\t\t\t\t\t\tshuffle=shuffle)\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                 \u001b[0;31m# test current model with cross-validation data and store results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/juliankimura/Google Drive/tensorflow/tfomics/tfomics/neuralnetwork.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(self, sess, data, batch_size, verbose, shuffle)\u001b[0m\n\u001b[1;32m    300\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_feed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_minibatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_feed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m                         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_calc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_feed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m                         \u001b[0mmetric\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m                         \u001b[0mperformance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/juliankimura/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/juliankimura/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/juliankimura/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/Users/juliankimura/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/juliankimura/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data = {'train': train, 'valid': valid, 'test': test}\n",
    "fit.train_minibatch(sess, nntrainer, data, batch_size=100, num_epochs=50, \n",
    "                      patience=20, verbose=2, shuffle=True, save_all=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model from:  ../../real_gneomic_representations/data/synthetic_TF_dataset/tmp/test_best.ckpt\n",
      "  test  loss:\t\t0.36129\n",
      "  test  accuracy:\t0.84027+/-0.00000\n",
      "  test  auc-roc:\t0.92014+/-0.00000\n",
      "  test  auc-pr:\t\t0.91335+/-0.00000\n"
     ]
    }
   ],
   "source": [
    "nntrainer.set_best_parameters(sess)\n",
    "\n",
    "test = {'inputs': X_test, 'targets': y_test}\n",
    "loss, mean_vals, std_vals = nntrainer.test_model(sess, test, batch_size=128, name='test', verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = nnmodel.get_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{<tf.Tensor 'is_training:0' shape=<unknown> dtype=bool>: False,\n",
       " <tf.Tensor 'Placeholder:0' shape=<unknown> dtype=float32>: 0.001,\n",
       " <tf.Tensor 'keep_prob_0:0' shape=<unknown> dtype=float32>: 1.0,\n",
       " <tf.Tensor 'inputs:0' shape=(?, 200, 1, 4) dtype=float32>: [],\n",
       " <tf.Tensor 'keep_prob_1:0' shape=<unknown> dtype=float32>: 1.0}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = {'inputs': X_test, 'targets': y_test}\n",
    "nntrainer.test_feed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-0.00350777, -0.00703558,  0.00535235, ..., -0.00426305,\n",
       "         0.00186531,  0.0053092 ], dtype=float32),\n",
       " array([-0.01504638, -0.00255676,  0.00442328,  0.01059202,  0.03387694,\n",
       "        -0.00236827, -0.01294479,  0.0256978 ,  0.00550709,  0.00934643,\n",
       "         0.01505037,  0.01004567,  0.03109215,  0.00361257,  0.01900271,\n",
       "        -0.01999425,  0.00580315, -0.00819865, -0.00436363, -0.0157215 ,\n",
       "        -0.0064188 ,  0.01047697,  0.01292237,  0.00525506,  0.01601962,\n",
       "         0.00991549,  0.0055623 ,  0.00213059, -0.00968827, -0.01860135,\n",
       "         0.0088518 ,  0.00856402], dtype=float32),\n",
       " array([-0.0160378 , -0.00695984,  0.00246645,  0.0106992 ,  0.0317835 ,\n",
       "        -0.00263872, -0.01740194,  0.02314704,  0.00798777,  0.0063303 ,\n",
       "         0.01554891,  0.0100847 ,  0.02810453,  0.00460645,  0.01817757,\n",
       "        -0.02146973,  0.00397175, -0.00814741, -0.00380266, -0.01858133,\n",
       "        -0.00376066,  0.00961024,  0.00779915,  0.00401985,  0.01365141,\n",
       "         0.00851226,  0.00305584,  0.00517832, -0.013941  , -0.01953641,\n",
       "         0.01181134,  0.01007557], dtype=float32),\n",
       " array([-0.00171578, -0.00229576, -0.00317339, ...,  0.00302044,\n",
       "        -0.00357835, -0.00611495], dtype=float32),\n",
       " array([-0.00179073, -0.00517585, -0.00057189,  0.01609215,  0.0056624 ,\n",
       "         0.01441294, -0.0033589 ,  0.00370886,  0.00054334,  0.00304557,\n",
       "         0.00589175,  0.00522007, -0.00034471,  0.00762754,  0.00927562,\n",
       "        -0.00233135, -0.00898609, -0.00677615,  0.01140032,  0.00144083,\n",
       "        -0.00449394, -0.0027435 ,  0.00407248,  0.00465092,  0.00641785,\n",
       "         0.00509218, -0.0025403 , -0.00420075,  0.00379097,  0.00454831,\n",
       "         0.00083014,  0.00916982,  0.00163019,  0.00280289, -0.00308395,\n",
       "         0.01355645,  0.00150078,  0.00125522, -0.0053382 , -0.00342162,\n",
       "         0.00029879, -0.00030773, -0.00784997, -0.0134511 ,  0.00615575,\n",
       "         0.00412488,  0.00281405,  0.00030048,  0.00471209,  0.00048702,\n",
       "         0.00356469,  0.0018331 ,  0.00697824,  0.00402165,  0.01895332,\n",
       "        -0.01080704,  0.00643869,  0.00131518,  0.00440928,  0.00056002,\n",
       "         0.0050121 ,  0.00313159, -0.00032334, -0.00235415], dtype=float32),\n",
       " array([-0.00218789, -0.00545188, -0.00071921,  0.01606734,  0.00327955,\n",
       "         0.0136577 , -0.0041052 ,  0.00215293,  0.00120956,  0.00376726,\n",
       "         0.00602221,  0.00458807, -0.00199419,  0.0081845 ,  0.00756046,\n",
       "        -0.00580184, -0.00831309, -0.00779552,  0.00687986,  0.0017514 ,\n",
       "        -0.00535344, -0.0041602 ,  0.00430722,  0.0015069 ,  0.0071449 ,\n",
       "         0.00656752, -0.00324226, -0.00415767,  0.00348944,  0.00318986,\n",
       "         0.00287561,  0.00842259,  0.00127591,  0.00039319, -0.00586171,\n",
       "         0.0095621 ,  0.00113733,  0.00024874, -0.00393185, -0.00541224,\n",
       "        -0.00071816,  0.00027284, -0.00770398, -0.01490874,  0.00497243,\n",
       "         0.00376365,  0.00105466, -0.00090713,  0.00272493,  0.00216507,\n",
       "         0.00304657,  0.00038234,  0.00528199,  0.00587874,  0.02087022,\n",
       "        -0.01023758,  0.00714412,  0.00048579,  0.00226329,  0.00091398,\n",
       "         0.00478555,  0.00163428, -0.00352595, -0.00463431], dtype=float32),\n",
       " array([-0.0009637 , -0.00385654, -0.02161553, ...,  0.00313114,\n",
       "        -0.00590584, -0.0125342 ], dtype=float32),\n",
       " array([-0.02451696], dtype=float32)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_data = test['targets'].shape[0]\n",
    "batch_generator = nn.BatchGenerator(num_data, 1000, True)\n",
    "nntrainer.test_feed = batch_generator.next_minibatch(test, nntrainer.test_feed, nntrainer.placeholders)\n",
    "\n",
    "dx = params\n",
    "dy = nnmodel.loss\n",
    "sess.run(tf.gradients(dy, dx), feed_dict=nntrainer.test_feed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'pred'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-ed639ca7c58e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mdy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnnmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhessians\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnntrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_feed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/juliankimura/anaconda/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py\u001b[0m in \u001b[0;36mhessians\u001b[0;34m(ys, xs, name, colocate_gradients_with_ops, gate_gradients, aggregation_method)\u001b[0m\n\u001b[1;32m    891\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_second_derivative'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    892\u001b[0m       \u001b[0;31m# Compute the partial derivatives with respect to each element of the list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 893\u001b[0;31m       \u001b[0m_hess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_gradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_gradient\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_gradients\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    894\u001b[0m       \u001b[0;31m# Pack the list into a matrix and add to the list of hessians\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    895\u001b[0m       \u001b[0mhessians\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_hess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/juliankimura/anaconda/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    891\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_second_derivative'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    892\u001b[0m       \u001b[0;31m# Compute the partial derivatives with respect to each element of the list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 893\u001b[0;31m       \u001b[0m_hess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_gradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_gradient\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_gradients\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    894\u001b[0m       \u001b[0;31m# Pack the list into a matrix and add to the list of hessians\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    895\u001b[0m       \u001b[0mhessians\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_hess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/juliankimura/anaconda/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py\u001b[0m in \u001b[0;36mgradients\u001b[0;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method)\u001b[0m\n\u001b[1;32m    472\u001b[0m                 \u001b[0mout_grads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloop_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZerosLike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m               \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 474\u001b[0;31m                 \u001b[0mout_grads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontrol_flow_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZerosLikeOutsideLoop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    475\u001b[0m           \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_grad\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m             \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/juliankimura/anaconda/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mZerosLikeOutsideLoop\u001b[0;34m(op, index)\u001b[0m\n\u001b[1;32m   1322\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m     \u001b[0mop_ctxt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_control_flow_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1324\u001b[0;31m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop_ctxt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1325\u001b[0m     \u001b[0mbranch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop_ctxt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbranch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0mswitch_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mswitch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbranch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'pred'"
     ]
    }
   ],
   "source": [
    "num_data = test['targets'].shape[0]\n",
    "batch_generator = nn.BatchGenerator(num_data, 1000, True)\n",
    "nntrainer.test_feed = batch_generator.next_minibatch(test, nntrainer.test_feed, nntrainer.placeholders)\n",
    "\n",
    "dx = params\n",
    "dy = nnmodel.loss\n",
    "sess.run(tf.hessians(dy, dx), feed_dict=nntrainer.test_feed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.ops.variables.Variable at 0x121596748>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x1215b4f98>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x121595fd0>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x105b5acf8>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x106dbfe80>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x128106a58>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x106e83438>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x106ea1908>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W = nnmodel.get_parameters(sess, layer='conv1d_0')[0]\n",
    "W = np.squeeze(W.transpose([3, 2, 0, 1]))\n",
    "fig, plt = visualize.plot_filter_logos(W, normalize=True, figsize=(100,50), height=25, \n",
    "                            nt_width=10, norm=0, alphabet='dna')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# sequence to perform saliency analysis\n",
    "index = 1\n",
    "X = np.expand_dims(X_test[index], axis=0)\n",
    "\n",
    "# parameters for saliency analysis\n",
    "params = {'genome_model': model, \n",
    "          'input_shape': input_shape, \n",
    "          'output_shape': output_shape, \n",
    "          'model_path': file_path+'_best.ckpt',\n",
    "          'optimization': optimization\n",
    "         }\n",
    "\n",
    "# backprop saliency\n",
    "backprop_saliency = saliency.backprop(X, layer='output', class_index=0, params=params)\n",
    "\n",
    "# guided backprop saliency\n",
    "guided_saliency = saliency.guided_backprop(X, layer='output', class_index=0, params=params)\n",
    "\n",
    "# stochastic guided backprop saliency\n",
    "stochastic_saliency = saliency.stochastic_guided_backprop(X, layer='output', class_index=0, params=params,\n",
    "                                                         num_average=200, threshold=1.0, stochastic_val=0.5)\n",
    "\n",
    "# plot saliency comparison\n",
    "fig, ax = plt.subplots(nrows=4, ncols=1, sharex=True, sharey=True, figsize=(15, 3));\n",
    "plt.subplot(4,1,1)\n",
    "visualize.plot_pos_saliency(np.squeeze(backprop_saliency[0]).T)    \n",
    "plt.ylabel(' backprop', fontsize=6)\n",
    "plt.subplot(4,1,2)\n",
    "visualize.plot_pos_saliency(np.squeeze(guided_saliency[0]).T)    \n",
    "plt.ylabel(' guided', fontsize=6)\n",
    "plt.subplot(4,1,3)\n",
    "visualize.plot_pos_saliency(np.squeeze(stochastic_saliency[0]).T)    \n",
    "plt.ylabel(' stochastic', fontsize=6)\n",
    "plt.subplot(4,1,4)\n",
    "visualize.plot_pos_saliency(np.squeeze(X).T)    \n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
