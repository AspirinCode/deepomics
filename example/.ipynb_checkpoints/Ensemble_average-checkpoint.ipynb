{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function \n",
    "import os, sys, h5py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from six.moves import cPickle\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve, accuracy_score, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "data_path = '/home/peter/Code/tensorflow/data'\n",
    "results_path = os.path.join(data_path, 'results', 'tfomics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "filename = 'valideval_dataset.hdf5'\n",
    "dataset = h5py.File(os.path.join(data_path,filename),'r')\n",
    "group_name = ['valid_data']\n",
    "val_dat = np.array(dataset['/'+group_name[0]+'/vs_valid'])\n",
    "val_lbl = np.array(dataset['/'+group_name[0]+'/label_valid'])\n",
    "\n",
    "fragLen = 330\n",
    "N = 14\n",
    "startgap = np.ceil(float(val_dat.shape[1] - fragLen)/N).astype('int')\n",
    "true_lbl = np.zeros((val_dat.shape[0]*val_dat.shape[0],), dtype='float32')\n",
    "\n",
    "cnt_ = 0\n",
    "for a in range(val_dat.shape[0]):\n",
    "    for b in range(val_dat.shape[0]):\n",
    "\n",
    "        # Keep track of the true labels\n",
    "        if val_lbl[a,b] == 1:\n",
    "            true_lbl[cnt_] = 1\n",
    "        else:\n",
    "            true_lbl[cnt_] = 0\n",
    "\n",
    "        cnt_ += 1        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 0\n",
      "auc: 0.935207313228\n",
      "model 1\n",
      "auc: 0.937158958118\n",
      "model 2\n",
      "auc: 0.941078560941\n",
      "equally-weighted ensemble\n",
      "auc: 0.94079469838\n"
     ]
    }
   ],
   "source": [
    "files = ['resid_model_old_data_1.pickle', \n",
    "         'resid_model_old_data_2.pickle', \n",
    "         'resid_model_deepomics_old_data_1.pickle',\n",
    "         'resid_model_new_data_2.pickle'\n",
    "        ]\n",
    "\n",
    "pred_lbl = []\n",
    "for filename in files:\n",
    "    savefile = os.path.join(results_path, filename)\n",
    "    f = open(savefile, 'rb')\n",
    "    pred_lbl.append(cPickle.load(f))\n",
    "    f.close()\n",
    "\n",
    "# Tim's model\n",
    "filename = 'predictions_dataset2_unscattered_1d_version_residual2_100_1000.txt'\n",
    "savefile = os.path.join(results_path, filename)\n",
    "df = pd.read_table(savefile, header=None)\n",
    "pred_lbl.append(df[0].as_matrix())\n",
    "pred_lbl = np.array(pred_lbl).T    \n",
    "\n",
    "num_models = pred_lbl.shape[1]\n",
    "    \n",
    "for i in range(num_models):\n",
    "    print('model ' + str(i))\n",
    "    fpr, tpr, thresholds = roc_curve(true_lbl, pred_lbl[:,i])\n",
    "    print('auc: ' + str(auc(fpr, tpr)))\n",
    "    \n",
    "fpr, tpr, thresholds = roc_curve(true_lbl, np.mean(pred_lbl, axis=1))\n",
    "print('equally-weighted ensemble')\n",
    "print('auc: ' + str(auc(fpr, tpr)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# random weight sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iterations: 0\n",
      "higher auc found: 0.941138716816\n",
      "higher auc found: 0.941198266405\n",
      "higher auc found: 0.941594265584\n",
      "higher auc found: 0.941615136383\n",
      "higher auc found: 0.941698704083\n",
      "iterations: 100\n",
      "higher auc found: 0.941710573888\n",
      "iterations: 200\n",
      "higher auc found: 0.941714425804\n",
      "iterations: 300\n",
      "higher auc found: 0.941717802243\n",
      "iterations: 400\n",
      "iterations: 500\n",
      "iterations: 600\n",
      "iterations: 700\n",
      "iterations: 800\n",
      "AUC: 0.941720947934\n",
      "[ 0.13868516  0.18303502  0.67827982]\n"
     ]
    }
   ],
   "source": [
    "patience = 500\n",
    "best_results = 0\n",
    "best_weights = 0\n",
    "\n",
    "global_counter = 0\n",
    "counter = 0\n",
    "status = True\n",
    "while status:    \n",
    "    if np.mod(global_counter, 100) == 0:\n",
    "        print('iterations: ' + str(global_counter))\n",
    "    w = np.random.rand(num_models)\n",
    "    w /= np.sum(w)\n",
    "    \n",
    "    prediction = 0\n",
    "    for i in range(pred_lbl.shape[1]):\n",
    "        prediction += pred_lbl[:,i]*w[i]\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(true_lbl, prediction)\n",
    "    score = auc(fpr, tpr)\n",
    "    \n",
    "    if score > best_results:\n",
    "        print('higher auc found: ' + str(score))\n",
    "        best_weights = w\n",
    "        best_results = score\n",
    "        counter = 0\n",
    "    counter += 1\n",
    "    global_counter += 1\n",
    "    if counter >= patience:\n",
    "        status = False\n",
    "        print('Finished searching')\n",
    "        \n",
    "print('AUC: ' + str(best_results))\n",
    "print(best_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian process weight sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iterations: 0\n",
      "higher auc found: 0.940438797262\n",
      "higher auc found: 0.940510472388\n",
      "higher auc found: 0.941234494984\n",
      "higher auc found: 0.941272078623\n",
      "higher auc found: 0.941336791615\n",
      "higher auc found: 0.941508028949\n",
      "higher auc found: 0.9416035102\n",
      "higher auc found: 0.941686634569\n",
      "higher auc found: 0.941709339829\n",
      "higher auc found: 0.941714458123\n",
      "higher auc found: 0.941716232211\n",
      "higher auc found: 0.941719403825\n",
      "higher auc found: 0.941719856365\n",
      "iterations: 100\n",
      "higher auc found: 0.94172083077\n",
      "higher auc found: 0.941721223364\n",
      "iterations: 200\n",
      "iterations: 300\n",
      "higher auc found: 0.941721298659\n",
      "iterations: 400\n",
      "higher auc found: 0.941721499816\n",
      "iterations: 500\n",
      "iterations: 600\n",
      "iterations: 700\n",
      "higher auc found: 0.941721505103\n",
      "iterations: 800\n",
      "iterations: 900\n",
      "higher auc found: 0.941721506723\n",
      "higher auc found: 0.941721508173\n",
      "higher auc found: 0.941721514312\n",
      "iterations: 1000\n",
      "iterations: 1100\n",
      "higher auc found: 0.941721518747\n",
      "iterations: 1200\n",
      "higher auc found: 0.941721520878\n",
      "higher auc found: 0.941721529064\n",
      "iterations: 1300\n",
      "higher auc found: 0.941721529491\n",
      "iterations: 1400\n",
      "higher auc found: 0.941721535545\n",
      "iterations: 1500\n",
      "higher auc found: 0.941721536057\n",
      "higher auc found: 0.941721540661\n",
      "iterations: 1600\n",
      "iterations: 1700\n",
      "higher auc found: 0.941721541173\n",
      "iterations: 1800\n",
      "higher auc found: 0.941721542111\n",
      "higher auc found: 0.941721544669\n",
      "iterations: 1900\n",
      "iterations: 2000\n",
      "iterations: 2100\n",
      "higher auc found: 0.941721545266\n",
      "higher auc found: 0.941721546545\n",
      "iterations: 2200\n",
      "higher auc found: 0.941721546801\n",
      "higher auc found: 0.941721547227\n",
      "iterations: 2300\n",
      "iterations: 2400\n",
      "iterations: 2500\n",
      "iterations: 2600\n",
      "higher auc found: 0.941721547483\n",
      "iterations: 2700\n",
      "higher auc found: 0.941721547739\n",
      "iterations: 2800\n",
      "higher auc found: 0.94172154791\n",
      "higher auc found: 0.94172154808\n",
      "higher auc found: 0.941721548165\n",
      "iterations: 2900\n",
      "iterations: 3000\n",
      "higher auc found: 0.941721548165\n",
      "iterations: 3100\n",
      "iterations: 3200\n",
      "higher auc found: 0.941721548165\n",
      "iterations: 3300\n",
      "iterations: 3400\n",
      "iterations: 3500\n",
      "iterations: 3600\n",
      "iterations: 3700\n",
      "Finished searching\n",
      "AUC: 0.941721548165\n",
      "[ 0.13563975  0.17697226  0.68738799]\n"
     ]
    }
   ],
   "source": [
    "patience = 500\n",
    "best_results = 0\n",
    "\n",
    "w = np.random.rand(num_models)\n",
    "w /= np.sum(w)\n",
    "best_weights = w\n",
    "sigma = .1\n",
    "\n",
    "global_counter = 0\n",
    "counter = 0\n",
    "status = True\n",
    "while status:    \n",
    "    if np.mod(global_counter, 100) == 0:\n",
    "        print('iterations: ' + str(global_counter))\n",
    "    w = np.zeros(num_models)\n",
    "    for i in range(num_models):\n",
    "        w[i] = np.maximum(best_weights[i] + sigma*np.random.randn(), 0.0001)\n",
    "    w /= np.sum(w)\n",
    "    \n",
    "    prediction = 0\n",
    "    for i in range(pred_lbl.shape[1]):\n",
    "        prediction += pred_lbl[:,i]*w[i]\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(true_lbl, prediction)\n",
    "    score = auc(fpr, tpr)\n",
    "    \n",
    "    if score > best_results:\n",
    "        print('higher auc found: ' + str(score))\n",
    "        best_weights = w\n",
    "        best_results = score\n",
    "        counter = 0\n",
    "    counter += 1\n",
    "    global_counter += 1\n",
    "    if counter >= patience:\n",
    "        status = False\n",
    "        print('Finished searching')\n",
    "        \n",
    "    if np.mod(counter, 100) == 0:\n",
    "        sigma /= 2\n",
    "        \n",
    "print('AUC: ' + str(best_results))\n",
    "print(best_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def test_prediction(nntrainer, data_path):\n",
    "\n",
    "    filename = 'competition_dataset_downsampled.hdf5'\n",
    "    dataset = h5py.File(os.path.join(data_path,filename),'r')\n",
    "    group_name = ['competition_data']\n",
    "    val_dat = np.array(dataset['/'+group_name[0]+'/realval'])\n",
    "    val_lbl = np.array(dataset['/'+group_name[0]+'/realtest'])\n",
    "\n",
    "    fragLen = 330\n",
    "    N = 14\n",
    "    avg_F = np.mean(val_dat,axis=0)\n",
    "\n",
    "    startgap = np.ceil(float(val_dat.shape[1] - fragLen)/N).astype('int')\n",
    "    true_lbl = np.zeros((val_dat.shape[0]*val_dat.shape[0],), dtype='float32')\n",
    "    pred_lbl = np.zeros((val_dat.shape[0]*val_dat.shape[0],), dtype='float32')\n",
    "\n",
    "    # Counter for the \"true_lbl\" array\n",
    "    cnt_ = 0\n",
    "    # Counter for the \"pred_lbl\" array\n",
    "    cnt_u = 0\n",
    "    for a in range(val_dat.shape[0]):\n",
    "        if a%100 == 0:\n",
    "            print('\\r' + 'X'*(a//100))\n",
    "\n",
    "        # Create batch array to send thru network\n",
    "        im_eval = np.empty((N*val_dat.shape[0],3,fragLen,1), dtype='float32')\n",
    "\n",
    "        # Count the number of traces in each batch\n",
    "        cnt = 0\n",
    "\n",
    "        for b in range(val_dat.shape[0]):\n",
    "\n",
    "            for n in range(0, val_dat.shape[1] - fragLen, startgap):\n",
    "                try:\n",
    "                    im_eval[cnt,:,:,0] = np.vstack((val_dat[a,n:n+fragLen],\n",
    "                                         val_dat[b,n:n+fragLen],\n",
    "                                         avg_F[n:n+fragLen]))\n",
    "                except:\n",
    "                    from IPython.core.debugger import Tracer\n",
    "                    Tracer()()\n",
    "\n",
    "                cnt += 1\n",
    "\n",
    "            # Keep track of the true labels\n",
    "            if val_lbl[a,b] == 1:\n",
    "                true_lbl[cnt_] = 1\n",
    "            else:\n",
    "                true_lbl[cnt_] = 0\n",
    "\n",
    "            cnt_ += 1\n",
    "\n",
    "        # Run batch through network\n",
    "        test = {'inputs': im_eval, 'keep_prob_conv': 1, 'keep_prob_dense': 1, 'is_training': False}\n",
    "        pred_stop = nntrainer.get_activations(test, layer='output')[:,0]\n",
    "        # Average output over each group of N traces\n",
    "        for u in range(0, len(pred_stop), N):\n",
    "            pred_lbl[cnt_u] = np.mean(pred_stop[u:u+N])\n",
    "            cnt_u += 1        \n",
    "    return pred_lbl\n",
    "\n",
    "\n",
    "nntrainer.set_best_parameters()\n",
    "pred_lbl = test_prediction(nntrainer, data_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
