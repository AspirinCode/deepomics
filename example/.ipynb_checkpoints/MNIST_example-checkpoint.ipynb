{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function \n",
    "import os, sys\n",
    "import numpy as np\n",
    "from six.moves import cPickle\n",
    "from collections import OrderedDict\n",
    "\n",
    "import tensorflow as tf\n",
    "sys.path.append('..')\n",
    "from tfomics import layers, utils, init, learn, explore\n",
    "from tfomics import neuralnetwork as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "\n",
    "X_train = mnist.train.images\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], 28, 28, 1))\n",
    "y_train = mnist.train.labels\n",
    "\n",
    "X_valid = mnist.validation.images\n",
    "X_valid = np.reshape(X_valid, (X_valid.shape[0], 28, 28, 1))\n",
    "y_valid = mnist.validation.labels\n",
    "\n",
    "X_test = mnist.test.images\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], 28, 28, 1))\n",
    "y_test = mnist.test.labels\n",
    "\n",
    "# get shapes\n",
    "num_data, height, widht, dim = X_train.shape\n",
    "input_shape=[None, height, widht, dim]\n",
    "num_labels = y_train.shape[1]   # number of labels (output units)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# design a neural network model\n",
    "inputs = utils.placeholder(shape=input_shape, name='input')\n",
    "targets = utils.placeholder(shape=(None,num_labels), name='output')\n",
    "is_training = tf.placeholder(tf.bool, name='is_training')   # variable to specify training or testing\n",
    "keep_prob = tf.placeholder(tf.float32, name='keep_prob')   # dropout probability\n",
    "\n",
    "# placeholder dictionary\n",
    "placeholders = {'inputs': inputs, \n",
    "                'targets': targets, \n",
    "                'keep_prob': keep_prob, \n",
    "                'is_training': is_training}\n",
    "\n",
    "net = OrderedDict()\n",
    "net['inputs'] = layers.InputLayer(inputs)\n",
    "net['conv1'] = layers.Conv2DLayer(net['inputs'], filter_size=(5,5), num_filters=32, padding='SAME')\n",
    "net['conv1_norm'] = layers.BatchNormLayer(net['conv1'], is_training)\n",
    "net['conv1_active'] = layers.ActivationLayer(net['conv1_norm'], function='relu')\n",
    "net['conv1_pool'] = layers.MaxPool2DLayer(net['conv1_active'], pool_size=(2,2))\n",
    "\n",
    "net['conv2'] = layers.Conv2DLayer(net['conv1_pool'], filter_size=(5,5), num_filters=64, \n",
    "                                  strides=(2,2), padding='VALID')\n",
    "net['conv2_norm'] = layers.BatchNormLayer(net['conv2'], is_training)\n",
    "net['conv2_active'] = layers.ActivationLayer(net['conv2_norm'], function='relu')\n",
    "net['conv2_dropout'] = layers.DropoutLayer(net['conv2_active'], keep_prob=keep_prob)\n",
    "\n",
    "net['dense1'] = layers.DenseLayer(net['conv2_dropout'], num_units=512, W=init.HeNormal(), b=None)\n",
    "net['dense1_norm'] = layers.BatchNormLayer(net['dense1'], is_training)\n",
    "net['dense1_active'] = layers.ActivationLayer(net['dense1_norm'], function='relu')\n",
    "net['dense1_dropout'] = layers.DropoutLayer(net['dense1_active'], keep_prob=keep_prob)\n",
    "\n",
    "net['dense2'] = layers.DenseLayer(net['dense1_dropout'], num_units=num_labels, \n",
    "                                  W=init.HeNormal(), b=init.Constant(0.05))\n",
    "net['output'] = layers.ActivationLayer(net['dense2'], function='sigmoid')\n",
    "\n",
    "optimization = {\"objective\": \"categorical\",  # (binary, categorical, squared_error)\n",
    "                \"optimizer\": \"adam\",    \n",
    "                \"learning_rate\": 0.001, # learning rate\n",
    "                \"clip_value\": True,     # clip prediction values (True for classification)\n",
    "                \"l2\": .00001            # l-2 weight decay\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------\n",
      "Network architecture:\n",
      "----------------------------------------------------------------------------\n",
      "layer1: inputs\n",
      "(?, 28, 28, 1)\n",
      "layer2: conv1\n",
      "(?, 28, 28, 32)\n",
      "layer3: conv1_norm\n",
      "(?, 28, 28, 32)\n",
      "layer4: conv1_active\n",
      "(?, 28, 28, 32)\n",
      "layer5: conv1_pool\n",
      "(?, 14, 14, 32)\n",
      "layer6: conv2\n",
      "(?, 5, 5, 64)\n",
      "layer7: conv2_norm\n",
      "(?, 5, 5, 64)\n",
      "layer8: conv2_active\n",
      "(?, 5, 5, 64)\n",
      "layer9: conv2_dropout\n",
      "(?, 5, 5, 64)\n",
      "layer10: dense1\n",
      "(?, 512)\n",
      "layer11: dense1_norm\n",
      "(?, 512)\n",
      "layer12: dense1_active\n",
      "(?, 512)\n",
      "layer13: dense1_dropout\n",
      "(?, 512)\n",
      "layer14: dense2\n",
      "(?, 10)\n",
      "layer15: output\n",
      "(?, 10)\n",
      "----------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# build neural network class\n",
    "nnmodel = nn.NeuralNet(net, placeholders)\n",
    "nnmodel.inspect_layers()\n",
    "\n",
    "# compile neural trainer\n",
    "filename = 'test'\n",
    "save_path = utils.make_directory('results','MNIST')\n",
    "filepath = os.path.join(save_path, filename)\n",
    "nntrainer = nn.NeuralTrainer(nnmodel, placeholders, optimization, save='best', filepath=filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# run session\n",
    "sess = tf.Session()\n",
    "\n",
    "# initialize variables\n",
    "sess.run(tf.initialize_all_variables())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=1.58961 -- accuracy=91.75%  \n",
      "  valid loss:\t\t1.52001\n",
      "  valid accuracy:\t0.99176+/-0.00211\n",
      "  valid auc-roc:\t0.99907+/-0.00085\n",
      "  valid auc-pr:\t\t0.99514+/-0.00350\n",
      "lower cross-validation found\n",
      "saving model to:  results/MNIST/test_best.ckpt\n",
      "Epoch 2 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=1.52461 -- accuracy=97.28%  \n",
      "  valid loss:\t\t1.50890\n",
      "  valid accuracy:\t0.99410+/-0.00231\n",
      "  valid auc-roc:\t0.99947+/-0.00054\n",
      "  valid auc-pr:\t\t0.99736+/-0.00187\n",
      "lower cross-validation found\n",
      "saving model to:  results/MNIST/test_best.ckpt\n",
      "Epoch 3 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=1.51230 -- accuracy=98.02%  \n",
      "  valid loss:\t\t1.50358\n",
      "  valid accuracy:\t0.99562+/-0.00198\n",
      "  valid auc-roc:\t0.99955+/-0.00046\n",
      "  valid auc-pr:\t\t0.99783+/-0.00135\n",
      "lower cross-validation found\n",
      "saving model to:  results/MNIST/test_best.ckpt\n",
      "Epoch 4 out of 500 \n",
      "[===========                   ] 35.3% -- time=3s -- loss=1.50642 -- accuracy=98.21%  "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-38eacdef5bc7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'valid'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mX2\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m learn.train_minibatch(sess, nntrainer, data, batch_size=128, num_epochs=500, \n\u001b[1;32m----> 6\u001b[1;33m                       patience=10, verbose=1, shuffle=True)\n\u001b[0m",
      "\u001b[1;32m/home/peter/Code/tensorflow/tfomics/tfomics/learn.pyc\u001b[0m in \u001b[0;36mtrain_minibatch\u001b[1;34m(sess, nntrainer, data, batch_size, num_epochs, patience, verbose, shuffle)\u001b[0m\n\u001b[0;32m     24\u001b[0m                                                                                         \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m                                                                                         \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m \t\t\t\t\t\t\t\t\t\t\tshuffle=shuffle)\n\u001b[0m\u001b[0;32m     27\u001b[0m                 \u001b[0mnntrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'train'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/peter/Code/tensorflow/tfomics/tfomics/neuralnetwork.pyc\u001b[0m in \u001b[0;36mtrain_epoch\u001b[1;34m(self, sess, feed_X, batch_size, verbose, shuffle)\u001b[0m\n\u001b[0;32m    134\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_batches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m                         \u001b[0mfeed_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_generator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext_minibatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeed_X\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 136\u001b[1;33m                         \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    137\u001b[0m                         \u001b[0mvalue\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_metric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtargets\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m                         \u001b[0mperformance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/peter/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    708\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    709\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 710\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    711\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    712\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/peter/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    906\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    907\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 908\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    909\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    910\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/peter/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    956\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    957\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m--> 958\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m    959\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    960\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32m/home/peter/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m    963\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    964\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 965\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    966\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    967\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/peter/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m    945\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m    946\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 947\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m    948\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# organize dataset to be just like placeholders list\n",
    "X = {'inputs': X_train, 'targets': y_train, 'keep_prob': 0.6, 'is_training': True}\n",
    "X2 = {'inputs': X_valid, 'targets': y_valid, 'keep_prob': 1, 'is_training': False}\n",
    "data = {'train': X, 'valid': X2}\n",
    "learn.train_minibatch(sess, nntrainer, data, batch_size=128, num_epochs=500, \n",
    "                      patience=10, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model from:  results/MNIST/test_best.ckpt\n",
      "  test  loss:\t\t1.50271\n",
      "  test  accuracy:\t0.99566+/-0.00170\n",
      "  test  auc-roc:\t0.99987+/-0.00008\n",
      "  test  auc-pr:\t\t0.99897+/-0.00063\n"
     ]
    }
   ],
   "source": [
    "# load best model\n",
    "nnmodel.load_model_parameters(sess, filepath+'_best.ckpt')\n",
    "\n",
    "test = {'inputs': X_test, 'targets': y_test, 'keep_prob': 1, 'is_training': False}\n",
    "test_loss = nntrainer.test_model(sess, test, batch_size=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Residual blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# design a neural network model\n",
    "input_vars = utils.placeholder(shape=input_shape, name='input')\n",
    "target_vars = utils.placeholder(shape=(None,num_labels), name='output')\n",
    "is_training = tf.placeholder(tf.bool, name='is_training')   # variable to specify training or testing\n",
    "keep_prob = tf.placeholder(tf.float32, name='keep_prob')   # dropout probability\n",
    "\n",
    "# placeholder dictionary\n",
    "placeholders = {'inputs': inputs, \n",
    "                'targets': targets, \n",
    "                'keep_prob': keep_prob, \n",
    "                'is_training': is_training}\n",
    "\n",
    "net = OrderedDict()\n",
    "net['inputs'] = layers.InputLayer(inputs)\n",
    "\n",
    "# 1st convolution layer\n",
    "net['conv1'] = layers.Conv2DLayer(net['inputs'], filter_size=(5,5), num_filters=32, padding='SAME')\n",
    "net['conv1_norm'] = layers.BatchNormLayer(net['conv1'], is_training)\n",
    "net['conv1_active'] = layers.ActivationLayer(net['conv1_norm'], function='relu')\n",
    "\n",
    "# residual block 1\n",
    "num_filters = 32\n",
    "filter_size = (5,5)\n",
    "last_layer = 'conv1_active'\n",
    "name = 'conv1_2'\n",
    "net[name+'_1resid'] = layers.Conv2DLayer(net[last_layer], filter_size=filter_size, num_filters=num_filters, padding='SAME')\n",
    "net[name+'_1resid_norm'] = layers.BatchNormLayer(net[name+'_1resid'], is_training)\n",
    "net[name+'_1resid_active'] = layers.ActivationLayer(net[name+'_1resid_norm'], function='relu')\n",
    "net[name+'_1resid_dropout'] = layers.DropoutLayer(net[name+'_1resid_active'], keep_prob=keep_prob)\n",
    "net[name+'_2resid'] = layers.Conv2DLayer(net[name+'_1resid_dropout'], filter_size=filter_size, num_filters=num_filters, padding='SAME')\n",
    "net[name+'_2resid_norm'] = layers.BatchNormLayer(net[name+'_2resid'], is_training)\n",
    "net[name+'_residual'] = layers.ElementwiseSumLayer([net[last_layer], net[name+'_2resid_norm']])\n",
    "net[name+'_resid'] = layers.ActivationLayer(net[name+'_residual'], function='relu')\n",
    "\n",
    "net['conv1_pool'] = layers.MaxPool2DLayer(net['conv1_2_resid'], pool_size=(2,2))\n",
    "net['conv1_dropout'] = layers.DropoutLayer(net['conv1_pool'], keep_prob=keep_prob)\n",
    "\n",
    "# 2nd convolution layer\n",
    "net['conv2'] = layers.Conv2DLayer(net['conv1_dropout'], filter_size=(5,5), num_filters=64, \n",
    "                                  strides=(1,1), padding='VALID')\n",
    "net['conv2_norm'] = layers.BatchNormLayer(net['conv2'], is_training)\n",
    "net['conv2_active'] = layers.ActivationLayer(net['conv2_norm'], function='relu')\n",
    "\n",
    "# residual block 2\n",
    "num_filters = 64\n",
    "filter_size = (5,5)\n",
    "last_layer = 'conv2_active'\n",
    "name = 'conv2_2'\n",
    "net[name+'_1resid'] = layers.Conv2DLayer(net[last_layer], filter_size=filter_size, num_filters=num_filters, padding='SAME')\n",
    "net[name+'_1resid_norm'] = layers.BatchNormLayer(net[name+'_1resid'], is_training)\n",
    "net[name+'_1resid_active'] = layers.ActivationLayer(net[name+'_1resid_norm'], function='relu')\n",
    "net[name+'_1resid_dropout'] = layers.DropoutLayer(net[name+'_1resid_active'], keep_prob=keep_prob)\n",
    "net[name+'_2resid'] = layers.Conv2DLayer(net[name+'_1resid_dropout'], filter_size=filter_size, num_filters=num_filters, padding='SAME')\n",
    "net[name+'_2resid_norm'] = layers.BatchNormLayer(net[name+'_2resid'], is_training)\n",
    "net[name+'_residual'] = layers.ElementwiseSumLayer([net[last_layer], net[name+'_2resid_norm']])\n",
    "net[name+'_resid'] = layers.ActivationLayer(net[name+'_residual'], function='relu')\n",
    "\n",
    "net['conv2_pool'] = layers.MaxPool2DLayer(net['conv2_2_resid'], pool_size=(2,2))\n",
    "net['conv2_dropout'] = layers.DropoutLayer(net['conv2_pool'], keep_prob=keep_prob)\n",
    "\n",
    "# dense layer 1\n",
    "net['dense1'] = layers.DenseLayer(net['conv2_dropout'], num_units=128, \n",
    "                                  W=init.HeNormal(), b=init.Constant(0.05))\n",
    "net['dense1_norm'] = layers.BatchNormLayer(net['dense1'], is_training)\n",
    "net['dense1_active'] = layers.ActivationLayer(net['dense1_norm'], function='relu')\n",
    "net['dense1_dropout'] = layers.DropoutLayer(net['dense1_active'], keep_prob=keep_prob)\n",
    "\n",
    "# dense layer 2\n",
    "net['dense2'] = layers.DenseLayer(net['dense1_dropout'], num_units=num_labels, \n",
    "                                  W=init.HeNormal(), b=init.Constant(0.05))\n",
    "net['output'] = layers.ActivationLayer(net['dense2'], function='softmax')\n",
    "\n",
    "\n",
    "optimization = {\"objective\": \"categorical\",  # (binary, categorical, squared_error)\n",
    "                \"optimizer\": \"adam\",    \n",
    "                \"learning_rate\": 0.001, # learning rate\n",
    "                \"clip_value\": True,     # clip prediction values (True for classification)\n",
    "                \"l2\": .00001            # l-2 weight decay\n",
    "                }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------\n",
      "Network architecture:\n",
      "----------------------------------------------------------------------------\n",
      "layer1: inputs\n",
      "(?, 28, 28, 1)\n",
      "layer2: conv1\n",
      "(?, 28, 28, 32)\n",
      "layer3: conv1_norm\n",
      "(?, 28, 28, 32)\n",
      "layer4: conv1_active\n",
      "(?, 28, 28, 32)\n",
      "layer5: conv1_2_1resid\n",
      "(?, 28, 28, 32)\n",
      "layer6: conv1_2_1resid_norm\n",
      "(?, 28, 28, 32)\n",
      "layer7: conv1_2_1resid_active\n",
      "(?, 28, 28, 32)\n",
      "layer8: conv1_2_1resid_dropout\n",
      "(?, 28, 28, 32)\n",
      "layer9: conv1_2_2resid\n",
      "(?, 28, 28, 32)\n",
      "layer10: conv1_2_2resid_norm\n",
      "(?, 28, 28, 32)\n",
      "layer11: conv1_2_residual\n",
      "(?, 28, 28, 32)\n",
      "layer12: conv1_2_resid\n",
      "(?, 28, 28, 32)\n",
      "layer13: conv1_pool\n",
      "(?, 14, 14, 32)\n",
      "layer14: conv1_dropout\n",
      "(?, 14, 14, 32)\n",
      "layer15: conv2\n",
      "(?, 10, 10, 64)\n",
      "layer16: conv2_norm\n",
      "(?, 10, 10, 64)\n",
      "layer17: conv2_active\n",
      "(?, 10, 10, 64)\n",
      "layer18: conv2_2_1resid\n",
      "(?, 10, 10, 64)\n",
      "layer19: conv2_2_1resid_norm\n",
      "(?, 10, 10, 64)\n",
      "layer20: conv2_2_1resid_active\n",
      "(?, 10, 10, 64)\n",
      "layer21: conv2_2_1resid_dropout\n",
      "(?, 10, 10, 64)\n",
      "layer22: conv2_2_2resid\n",
      "(?, 10, 10, 64)\n",
      "layer23: conv2_2_2resid_norm\n",
      "(?, 10, 10, 64)\n",
      "layer24: conv2_2_residual\n",
      "(?, 10, 10, 64)\n",
      "layer25: conv2_2_resid\n",
      "(?, 10, 10, 64)\n",
      "layer26: conv2_pool\n",
      "(?, 5, 5, 64)\n",
      "layer27: conv2_dropout\n",
      "(?, 5, 5, 64)\n",
      "layer28: dense1\n",
      "(?, 128)\n",
      "layer29: dense1_norm\n",
      "(?, 128)\n",
      "layer30: dense1_active\n",
      "(?, 128)\n",
      "layer31: dense1_dropout\n",
      "(?, 128)\n",
      "layer32: dense2\n",
      "(?, 10)\n",
      "layer33: output\n",
      "(?, 10)\n",
      "----------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# build neural network class\n",
    "nnmodel = nn.NeuralNet(net, placeholders)\n",
    "nnmodel.inspect_layers()\n",
    "\n",
    "# compile neural trainer\n",
    "filename = 'test_resnet'\n",
    "save_path = utils.make_directory('results','MNIST')\n",
    "filepath = os.path.join(save_path, filename)\n",
    "nntrainer = nn.NeuralTrainer(nnmodel, placeholders, optimization, \n",
    "                             save='best', filepath=filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=2.30580 -- accuracy=84.42%  \n",
      "  valid loss:\t\t2.30239\n",
      "  valid accuracy:\t0.90000+/-0.00752\n",
      "  valid auc-roc:\t0.99799+/-0.00049\n",
      "  valid auc-pr:\t\t0.93699+/-0.00836\n",
      "lower cross-validation found\n",
      "saving model to:  results/MNIST/test_resnet_best.ckpt\n",
      "Epoch 2 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=2.30215 -- accuracy=97.13%  \n",
      "  valid loss:\t\t2.30194\n",
      "  valid accuracy:\t0.90000+/-0.00752\n",
      "  valid auc-roc:\t0.99789+/-0.00060\n",
      "  valid auc-pr:\t\t0.93678+/-0.00889\n",
      "lower cross-validation found\n",
      "saving model to:  results/MNIST/test_resnet_best.ckpt\n",
      "Epoch 3 out of 500 \n",
      "[========                      ] 27.2% -- time=16s -- loss=2.30194 -- accuracy=97.31%  "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-a7456e4ea346>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'valid'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mX2\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m learn.train_minibatch(sess, nntrainer, data, batch_size=128, num_epochs=500, \n\u001b[1;32m---> 12\u001b[1;33m                       patience=10, verbose=1, shuffle=True)\n\u001b[0m",
      "\u001b[1;32m/home/peter/Code/tensorflow/tfomics/tfomics/learn.pyc\u001b[0m in \u001b[0;36mtrain_minibatch\u001b[1;34m(sess, nntrainer, data, batch_size, num_epochs, patience, verbose, shuffle)\u001b[0m\n\u001b[0;32m     24\u001b[0m                                                                                         \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m                                                                                         \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m \t\t\t\t\t\t\t\t\t\t\tshuffle=shuffle)\n\u001b[0m\u001b[0;32m     27\u001b[0m                 \u001b[0mnntrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'train'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/peter/Code/tensorflow/tfomics/tfomics/neuralnetwork.pyc\u001b[0m in \u001b[0;36mtrain_epoch\u001b[1;34m(self, sess, feed_X, batch_size, verbose, shuffle)\u001b[0m\n\u001b[0;32m    134\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_batches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m                         \u001b[0mfeed_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_generator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext_minibatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeed_X\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 136\u001b[1;33m                         \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    137\u001b[0m                         \u001b[0mvalue\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_metric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtargets\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m                         \u001b[0mperformance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/peter/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    708\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    709\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 710\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    711\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    712\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/peter/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    906\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    907\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 908\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    909\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    910\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/peter/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    956\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    957\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m--> 958\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m    959\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    960\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32m/home/peter/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m    963\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    964\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 965\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    966\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    967\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/peter/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m    945\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m    946\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 947\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m    948\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# run session\n",
    "sess = tf.Session()\n",
    "\n",
    "# initialize variables\n",
    "sess.run(tf.initialize_all_variables())\n",
    "\n",
    "# organize dataset to be just like placeholders list\n",
    "X = {'inputs': X_train, 'targets': y_train, 'keep_prob': 0.6, 'is_training': True}\n",
    "X2 = {'inputs': X_valid, 'targets': y_valid, 'keep_prob': 1, 'is_training': False}\n",
    "data = {'train': X, 'valid': X2}\n",
    "learn.train_minibatch(sess, nntrainer, data, batch_size=128, num_epochs=500, \n",
    "                      patience=10, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load best model\n",
    "nnmodel.load_model_parameters(sess, filepath+'_best.ckpt')\n",
    "\n",
    "test = {'inputs': X_test, 'targets': y_test, 'keep_prob': 1, 'is_training': False}\n",
    "test_loss = nntrainer.test_model(sess, test, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
