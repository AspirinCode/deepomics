{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function \n",
    "import os, sys, h5py\n",
    "import numpy as np\n",
    "from six.moves import cPickle\n",
    "from collections import OrderedDict\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "sys.path.append('..')\n",
    "from tfomics import layers, utils, init, learn, explore\n",
    "from tfomics import neuralnetwork as nn\n",
    "from tfomics.build_network import *\n",
    "\n",
    "# import models\n",
    "from model_zoo import simple_connectomics_model_explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.3 s, sys: 6.18 s, total: 7.48 s\n",
      "Wall time: 8.42 s\n"
     ]
    }
   ],
   "source": [
    "filename = 'processed_dataset.hdf5'\n",
    "data_path = '/Users/juliankimura/Desktop/tensorflow/data'\n",
    "filepath = os.path.join(data_path,filename)\n",
    "\n",
    "group_name = ['processed_data']\n",
    "dataset = h5py.File(filepath,'r')\n",
    "%time dtf = np.array(dataset['/'+group_name[0]+'/dtf'])\n",
    "ltf = np.array(dataset['/'+group_name[0]+'/ltf'])\n",
    "dtf_crossval = np.array(dataset['/'+group_name[0]+'/dtf_crossval'])\n",
    "ltf_crossval = np.array(dataset['/'+group_name[0]+'/ltf_crossval'])\n",
    "\n",
    "X_train = dtf.transpose([0,2,3,1])\n",
    "y_train = ltf\n",
    "X_valid = dtf_crossval.transpose([0,2,3,1])\n",
    "y_valid = ltf_crossval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def model(input_shape, num_labels):\n",
    "\n",
    "    # placeholders\n",
    "    inputs = utils.placeholder(shape=input_shape, name='input')\n",
    "    is_training = tf.placeholder(tf.bool, name='is_training')\n",
    "    keep_prob = tf.placeholder(tf.float32, name='keep_prob')\n",
    "    targets = utils.placeholder(shape=(None,num_labels), name='output')\n",
    "\n",
    "    # placeholder dictionary\n",
    "    placeholders = {'inputs': inputs, \n",
    "                    'targets': targets, \n",
    "                    'keep_prob': keep_prob, \n",
    "                    'is_training': is_training}\n",
    "\n",
    "    # create model\n",
    "    layer1 = {'layer': 'input',\n",
    "                'inputs': inputs,\n",
    "              'name': 'input'\n",
    "                }\n",
    "    layer2 = {'layer': 'conv1d', \n",
    "                'num_filters': {'start': 25, 'bounds': [1, 200], 'scale': 20},\n",
    "                'filter_size': {'start': 9, 'bounds': [3, 27], 'scale': 10, 'multiples': 2, 'offset': 1},\n",
    "                'norm': 'batch',\n",
    "                'padding': 'SAME',\n",
    "                'activation': 'relu',\n",
    "                'pool_size': {'start': 2, 'bounds': [1, 20], 'scale': 6, 'multiples': 2},\n",
    "                'name': 'conv1'\n",
    "                }\n",
    "    layer3 = {'layer': 'conv1d', \n",
    "                'num_filters': {'start': 50, 'bounds': [1, 200], 'scale': 30},\n",
    "                'filter_size': {'start': 7, 'bounds': [3, 23], 'scale': 10, 'multiples': 2, 'offset': 1},\n",
    "                'norm': 'batch',\n",
    "                'padding': 'SAME',\n",
    "                'activation': 'relu',\n",
    "                'pool_size': {'start': 2, 'bounds': [1, 10], 'scale': 4, 'multiples': 2},\n",
    "                'name': 'conv1'\n",
    "                }\n",
    "    layer4 = {'layer': 'dense', \n",
    "                'num_units': {'start': 64, 'bounds': [16, 1000], 'scale': 50},\n",
    "                'norm': 'batch',\n",
    "                'activation': 'relu',\n",
    "                'name': 'dense1'\n",
    "                }\n",
    "    layer5 = {'layer': 'dense', \n",
    "              'num_units': num_labels,\n",
    "              'activation': 'sigmoid',\n",
    "              'name': 'dense2'\n",
    "                }\n",
    "\n",
    "    #from tfomics import build_network\n",
    "    model_layers = [layer1, layer2, layer3, layer4, layer5]\n",
    "\n",
    "    # optimization parameters\n",
    "    optimization = {\"objective\": \"binary\",\n",
    "                    \"optimizer\": \"adam\",\n",
    "                    \"learning_rate\": 0.001,\n",
    "                    \"l2\": 1e-6,\n",
    "                    #\"learning_rate\": {'start': -3, 'bounds': [-4, -1], 'scale': 1.5, 'transform': 'log'},      \n",
    "                    #\"l2\": {'start': -6, 'bounds': [-8, -2], 'scale': 3, 'transform': 'log'},\n",
    "                    # \"l1\": 0, \n",
    "                    }\n",
    "    return model_layers, placeholders, optimization\n",
    "\n",
    "\n",
    "# build network\n",
    "input_shape = list(X_train.shape)\n",
    "input_shape[0] = None\n",
    "num_labels = y_train.shape[1]\n",
    "model_layers, placeholders, optimization = model(input_shape, num_labels)\n",
    "\n",
    "# build neural opti\n",
    "optimizer = explore.NeuralOptimizer(model_layers, placeholders, optimization)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'inputs': <tf.Tensor 'input_1:0' shape=(?, 330, 1, 3) dtype=float32>,\n",
       "  'layer': 'input',\n",
       "  'name': 'input'},\n",
       " {'activation': 'relu',\n",
       "  'filter_size': 6,\n",
       "  'layer': 'conv1d',\n",
       "  'name': 'conv1',\n",
       "  'norm': 'batch',\n",
       "  'num_filters': 36,\n",
       "  'padding': 'SAME',\n",
       "  'pool_size': 16},\n",
       " {'activation': 'relu',\n",
       "  'filter_size': 18,\n",
       "  'layer': 'conv1d',\n",
       "  'name': 'conv1',\n",
       "  'norm': 'batch',\n",
       "  'num_filters': 18,\n",
       "  'padding': 'SAME',\n",
       "  'pool_size': 2},\n",
       " {'activation': 'relu',\n",
       "  'layer': 'dense',\n",
       "  'name': 'dense1',\n",
       "  'norm': 'batch',\n",
       "  'num_units': 86},\n",
       " {'activation': 'sigmoid', 'layer': 'dense', 'name': 'dense2', 'num_units': 2}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer.sample_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------\n",
      "Running baseline model\n",
      "\n",
      "Model layers:\n",
      "name: input\n",
      "pool_size: 2\n",
      "name: conv1\n",
      "num_filters: 25\n",
      "filter_size: 9\n",
      "pool_size: 2\n",
      "name: conv1\n",
      "num_filters: 50\n",
      "filter_size: 7\n",
      "name: dense1\n",
      "num_units: 64\n",
      "name: dense2\n",
      "num_units: 2\n",
      "\n",
      "Optimization:\n",
      "learning_rate: 0.001\n",
      "l2: 1e-06\n",
      "\n",
      "Epoch 1 out of 5 \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# optimize model parameters\n",
    "train = {'inputs': X_train, 'targets': y_train, 'keep_prob': 0.8, 'is_training': True}\n",
    "valid = {'inputs': X_valid, 'targets': y_valid, 'keep_prob': 1, 'is_training': False}        \n",
    "optimizer.optimize(train, valid, num_trials=20, num_epochs=5, batch_size=128, verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save optimal model\n",
    "optimizer.print_optimal_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
