{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function \n",
    "import os, sys\n",
    "import numpy as np\n",
    "from six.moves import cPickle\n",
    "from collections import OrderedDict\n",
    "\n",
    "import tensorflow as tf\n",
    "sys.path.append('..')\n",
    "from tfomics import neuralnetwork as nn\n",
    "from tfomics import neuralbuild as nb\n",
    "from tfomics import utils, fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "\n",
    "X_train = mnist.train.images\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], 28, 28, 1))\n",
    "y_train = mnist.train.labels\n",
    "\n",
    "X_valid = mnist.validation.images\n",
    "X_valid = np.reshape(X_valid, (X_valid.shape[0], 28, 28, 1))\n",
    "y_valid = mnist.validation.labels\n",
    "\n",
    "X_test = mnist.test.images\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], 28, 28, 1))\n",
    "y_test = mnist.test.labels\n",
    "\n",
    "# get shapes\n",
    "num_data, height, widht, dim = X_train.shape\n",
    "input_shape=[None, height, widht, dim]\n",
    "num_labels = y_train.shape[1]   # number of labels (output units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def model(input_shape, output_shape):\n",
    "\n",
    "    # create model\n",
    "    layer1 = {'layer': 'input',\n",
    "            'input_shape': input_shape,\n",
    "            }\n",
    "    layer2 = {'layer': 'conv2d', \n",
    "            'num_filters': 32,\n",
    "            'filter_size': (5, 5),\n",
    "            'norm': 'batch',\n",
    "            'activation': 'prelu',\n",
    "            'dropout': 0.1,\n",
    "            }\n",
    "    layer3 = {'layer': 'conv2d', \n",
    "            'num_filters': 64,\n",
    "            'filter_size': (5, 5),\n",
    "            'norm': 'batch',\n",
    "            'activation': 'prelu',\n",
    "            'dropout': 0.1,\n",
    "            }\n",
    "    layer4 = {'layer': 'dense', \n",
    "            'num_units': 512,\n",
    "            'activation': 'prelu',\n",
    "            'dropout': 0.5,\n",
    "            }  \n",
    "    layer5 = {'layer': 'dense', \n",
    "            'num_units': num_labels,\n",
    "            'activation': 'softmax',\n",
    "            }\n",
    "\n",
    "    #from tfomics import build_network\n",
    "    model_layers = [layer1, layer2, layer3, layer4, layer5]\n",
    "\n",
    "    # optimization parameters\n",
    "    optimization = {\"objective\": \"categorical\",\n",
    "                  \"optimizer\": \"adam\",\n",
    "                  \"learning_rate\": 0.001,      \n",
    "                  \"l2\": 1e-6,\n",
    "                  }\n",
    "    return model_layers, optimization\n",
    "\n",
    "\n",
    "\n",
    "# get shapes\n",
    "num_data, height, width, dim = X_train.shape\n",
    "input_shape=[None, height, width, dim]\n",
    "output_shape = y_train.shape\n",
    "\n",
    "model_layers, optimization = model(input_shape, output_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# set output file paths\n",
    "data_path = 'MNIST_data'\n",
    "filename = 'MNIST'\n",
    "save_path = utils.make_directory(data_path, filename)\n",
    "filepath = os.path.join(save_path, filename)\n",
    "\n",
    "# build neural network class\n",
    "nnmodel = nn.NeuralNet()\n",
    "nnmodel.build_layers(model_layers, optimization)\n",
    "nnmodel.inspect_layers()\n",
    "\n",
    "# compile neural trainer\n",
    "nntrainer = nn.NeuralTrainer(nnmodel, save='best', filepath=filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = utils.initialize_session(nnmodel.placeholders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 out of 50 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.41882 -- accuracy=91.36%   \n",
      "  valid loss:\t\t0.08885\n",
      "  valid accuracy:\t0.99492+/-0.00162\n",
      "  valid auc-roc:\t0.99953+/-0.00035\n",
      "  valid auc-pr:\t\t0.99682+/-0.00182\n",
      "  lower cross-validation found\n",
      "  saving model to:  MNIST_data/MNIST/MNIST_best.ckpt\n",
      "Epoch 2 out of 50 \n",
      "[==                            ] 7.3% -- time=249s -- loss=0.07755 -- accuracy=97.63%  "
     ]
    }
   ],
   "source": [
    "train = {'inputs': X_train, 'targets': y_train}\n",
    "valid = {'inputs': X_valid, 'targets': y_valid}\n",
    "data = {'train': train, 'valid': valid}\n",
    "results = fit.train_minibatch(sess, nntrainer, data, batch_size=200, num_epochs=50, \n",
    "                              patience=20, verbose=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nntrainer.set_best_parameters(sess)\n",
    "\n",
    "test = {'inputs': X_test, 'targets': y_test}\n",
    "loss, mean_vals, std_vals = nntrainer.test_model(sess, test, batch_size=128, name='test', verbose=1)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
